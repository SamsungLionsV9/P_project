"""
ìˆ˜ì…ì°¨ ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸ - ìµœì¢… ì†”ë£¨ì…˜
ìˆ˜ì…ì°¨ íŠ¹ì„±ì— ìµœì í™”:
- ë¸Œëœë“œ ê³„ì¸µ ì„¸ë¶„í™” (ëŸ­ì…”ë¦¬/í”„ë¦¬ë¯¸ì—„/ì¼ë°˜)
- ë¸Œëœë“œ êµ­ì  êµ¬ë¶„ (ë…ì¼/ì¼ë³¸/ë¯¸êµ­)
- ê°•í™”ëœ Target Encoding
- ì˜µì…˜ ì¤‘ìš”ë„ ê·¹ëŒ€í™”
"""
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
import xgboost as xgb
import joblib
import os
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

print("="*80)
print("ğŸŒ ìˆ˜ì…ì°¨ ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸ - ìµœì¢… ì†”ë£¨ì…˜")
print("="*80)
print()

# ========== 1. ë°ì´í„° ë¡œë“œ ==========
print("ğŸ“‚ Step 1: ë°ì´í„° ë¡œë“œ...")

df_raw = pd.read_csv('encar_imported_data.csv')
df_detail = pd.read_csv('data/complete_imported_details.csv')
df = df_raw.merge(df_detail, left_on='Id', right_on='car_id', how='inner')

print(f"âœ“ ìˆ˜ì…ì°¨ ë°ì´í„°: {len(df):,}í–‰")

# ========== 2. ì „ì²˜ë¦¬ ==========
print("\nğŸ”§ Step 2: ì „ì²˜ë¦¬...")

df = df.dropna(subset=['Price', 'Mileage', 'Year', 'Manufacturer', 'Model'])

# ìˆ˜ì…ì°¨ ê°€ê²© ë²”ìœ„ (ë” ë„“ìŒ)
df = df[df['Price'] > 300]
df = df[df['Price'] < 30000]  # 3ì–µ ì´í•˜
df = df[df['Mileage'] < 500000]
df = df[df['Year'] >= 2005]

# ë¡œê·¸ ë³€í™˜
df['Price_log'] = np.log1p(df['Price'])
print(f"âœ“ ì „ì²˜ë¦¬ í›„: {len(df):,}í–‰")

# ========== 3. ìˆ˜ì…ì°¨ íŠ¹í™” Feature Engineering (Part 1) ==========
print("\nâ­ Step 3: ìˆ˜ì…ì°¨ íŠ¹í™” Feature Engineering...")

# ë¸Œëœë“œ ê³„ì¸µ (ìˆ˜ì…ì°¨ëŠ” ë” ì„¸ë¶„í™”)
luxury_brands = ['ë²¤ì¸ ', 'Mercedes', 'BMW', 'ì•„ìš°ë””', 'Audi', 'ë ‰ì„œìŠ¤', 'Lexus', 
                 'í¬ë¥´ì‰', 'Porsche', 'ì œë„¤ì‹œìŠ¤', 'Genesis', 'í…ŒìŠ¬ë¼', 'Tesla']
premium_brands = ['ë³¼ë³´', 'Volvo', 'ì¬ê·œì–´', 'Jaguar', 'ëœë“œë¡œë²„', 'Land Rover', 
                  'ìºë”œë½', 'Cadillac', 'Infiniti', 'ì¸í”¼ë‹ˆí‹°']
standard_brands = ['í­ìŠ¤ë°”ê²', 'Volkswagen', 'í‘¸ì¡°', 'Peugeot', 'ì‹œíŠ¸ë¡œì—¥', 'Citroen',
                   'Mini', 'ë¯¸ë‹ˆ', 'Jeep', 'ì§€í”„']

def classify_brand_tier(brand):
    brand = str(brand).lower()
    if any(b.lower() in brand for b in luxury_brands):
        return 'luxury'
    elif any(b.lower() in brand for b in premium_brands):
        return 'premium'
    elif any(b.lower() in brand for b in standard_brands):
        return 'standard'
    return 'budget'

df['brand_tier'] = df['Manufacturer'].apply(classify_brand_tier)

# ë¸Œëœë“œ êµ­ì  (ê°ê°€ìœ¨/ì‹ ë¢°ë„ ë‹¤ë¦„)
german_brands = ['ë²¤ì¸ ', 'Mercedes', 'BMW', 'ì•„ìš°ë””', 'Audi', 'í­ìŠ¤ë°”ê²', 'Volkswagen', 'í¬ë¥´ì‰']
japanese_brands = ['ë ‰ì„œìŠ¤', 'Lexus', 'í† ìš”íƒ€', 'Toyota', 'í˜¼ë‹¤', 'Honda', 'ë‹›ì‚°', 'Nissan', 
                   'ì¸í”¼ë‹ˆí‹°', 'Infiniti', 'ë§ˆì¯”ë‹¤', 'Mazda', 'ìŠ¤ë°”ë£¨']
american_brands = ['í…ŒìŠ¬ë¼', 'Tesla', 'ìºë”œë½', 'Cadillac', 'Jeep', 'ì§€í”„', 'ì‰ë³´ë ˆ', 'Chevrolet']
european_brands = ['ë³¼ë³´', 'Volvo', 'í‘¸ì¡°', 'Peugeot', 'ì‹œíŠ¸ë¡œì—¥', 'ì¬ê·œì–´', 'ëœë“œë¡œë²„', 'Mini']

def classify_origin(brand):
    brand = str(brand).lower()
    if any(b.lower() in brand for b in german_brands):
        return 'german'
    elif any(b.lower() in brand for b in japanese_brands):
        return 'japanese'
    elif any(b.lower() in brand for b in american_brands):
        return 'american'
    elif any(b.lower() in brand for b in european_brands):
        return 'european'
    return 'other'

df['brand_origin'] = df['Manufacturer'].apply(classify_origin)

print(f"âœ“ ë¸Œëœë“œ ê³„ì¸µ ë¶„ë¥˜ ì™„ë£Œ")

# ========== 4. Target Encoding ==========
print("\nğŸ¯ Step 4: Target Encoding...")

# Train/Test ë¶„ë¦¬
train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)

# ë¶„ë¦¬ ë§ˆì»¤
train_df['is_train'] = 1
test_df['is_train'] = 0

# Target Encoding í•¨ìˆ˜
def create_target_encoding(train, test, col, target='Price_log', min_samples=10):
    global_mean = train[target].mean()
    agg = train.groupby(col)[target].agg(['mean', 'count'])
    counts = agg['count']
    means = agg['mean']
    
    # Smoothing
    smooth = 1 / (1 + np.exp(-(counts - min_samples) / 5))
    encoded = global_mean * (1 - smooth) + means * smooth
    
    train[f'{col}_target_enc'] = train[col].map(encoded).fillna(global_mean)
    test[f'{col}_target_enc'] = test[col].map(encoded).fillna(global_mean)
    
    return train, test, encoded

# Manufacturer Target Encoding (ìˆ˜ì…ì°¨ëŠ” ë¸Œëœë“œê°€ ë§¤ìš° ì¤‘ìš”!)
train_df, test_df, brand_encoding = create_target_encoding(
    train_df, test_df, 'Manufacturer', 'Price_log', min_samples=50
)
print(f"âœ“ Manufacturer Target Encoding")

# Model Target Encoding
train_df, test_df, model_encoding = create_target_encoding(
    train_df, test_df, 'Model', 'Price_log', min_samples=20
)
print(f"âœ“ Model Target Encoding")

# ë°ì´í„° í•©ì¹˜ê¸°
df = pd.concat([train_df, test_df], ignore_index=True)

# ========== 5. Feature Engineering (Part 2) ==========
print("\nâš™ï¸ Step 5: Feature Engineering (Part 2)...")

current_year = 2025
df['age'] = current_year - df['Year']
df['age_squared'] = df['age'] ** 2
df['age_cubed'] = df['age'] ** 3

# Mileage
df['mileage_per_year'] = df['Mileage'] / (df['age'] + 1)
df['mileage_log'] = np.log1p(df['Mileage'])
df['mileage_squared'] = df['Mileage'] ** 2

# ì˜µì…˜ (ìˆ˜ì…ì°¨ëŠ” ì˜µì…˜ì´ ë§¤ìš° ì¤‘ìš”!)
option_cols = [
    'has_sunroof', 'has_navigation', 'has_leather_seat', 'has_smart_key', 
    'has_rear_camera', 'has_led_lamp', 'has_parking_sensor', 'has_auto_ac',
    'has_heated_seat', 'has_ventilated_seat'
]

for col in option_cols:
    df[col] = df[col].fillna(0)

df['option_score'] = df[option_cols].sum(axis=1)
df['option_rate'] = df['option_score'] / 10

# ìˆ˜ì…ì°¨ í”„ë¦¬ë¯¸ì—„ ì˜µì…˜ ê°€ì¤‘ì¹˜ (ë” ë†’ê²Œ)
premium_weights = {
    'has_sunroof': 2.5,
    'has_ventilated_seat': 2.5,
    'has_led_lamp': 2.0,
    'has_leather_seat': 2.0,
    'has_navigation': 1.5,
    'has_smart_key': 1.5,
    'has_rear_camera': 1.2,
    'has_parking_sensor': 1.2,
    'has_auto_ac': 1.0,
    'has_heated_seat': 1.0
}

df['option_weighted'] = sum(df[col] * weight for col, weight in premium_weights.items())

# ì„±ëŠ¥ ë“±ê¸‰
grade_map = {'excellent': 3, 'good': 2, 'normal': 1}
df['inspection_score'] = df['inspection_grade'].map(grade_map).fillna(1)

# ì™„ë²½í•œ ì¡°ê±´
df['is_premium_condition'] = (
    (df['is_accident_free'] == 1) & 
    (df['inspection_score'] == 3) &
    (df['mileage_per_year'] < 12000)  # ìˆ˜ì…ì°¨ëŠ” ë” ì—¬ìœ ë¡­ê²Œ
).astype(int)

df['is_full_option'] = (df['option_score'] >= 8).astype(int)

# ì§€ì—­
df['region'] = df['region'].fillna('Unknown')
df['is_metro'] = (
    (df['region'].str.contains('ì„œìš¸')) | 
    (df['region'].str.contains('ê²½ê¸°'))
).astype(int)

# ì—°ë£Œ (ìˆ˜ì…ì°¨ëŠ” ë””ì ¤/í•˜ì´ë¸Œë¦¬ë“œê°€ í”„ë¦¬ë¯¸ì—„)
df['is_diesel'] = (df['FuelType'].str.contains('ë””ì ¤|ê²½ìœ ', case=False, na=False)).astype(int)
df['is_hybrid'] = (df['FuelType'].str.contains('í•˜ì´ë¸Œë¦¬ë“œ|ì „ê¸°', case=False, na=False)).astype(int)
df['is_eco_fuel'] = (df['is_diesel'] | df['is_hybrid']).astype(int)

# ìƒí˜¸ì‘ìš© (ì¤‘ìš”!)
df['brand_option_interaction'] = df['Manufacturer_target_enc'] * df['option_weighted']
df['model_option_interaction'] = df['Model_target_enc'] * df['option_weighted']
df['age_option_interaction'] = df['age'] * df['option_rate']
df['age_mileage_interaction'] = df['age'] * df['mileage_log']
df['tier_option_interaction'] = df['brand_tier'].map({
    'luxury': 4, 'premium': 3, 'standard': 2, 'budget': 1
}) * df['option_weighted']

# ê°€ê²© êµ¬ê°„
price_bins = pd.qcut(df['Price'], q=10, labels=False, duplicates='drop')
df['price_segment'] = price_bins

print(f"âœ“ Feature Engineering ì™„ë£Œ")

# ========== 6. Label Encoding ==========
print("\nğŸ·ï¸ Step 6: ì¹´í…Œê³ ë¦¬ ì¸ì½”ë”©...")

encoders = {}
for col in ['FuelType', 'brand_tier', 'brand_origin']:
    if col in df.columns:
        le = LabelEncoder()
        df[f'{col}_encoded'] = le.fit_transform(df[col].astype(str))
        encoders[col] = le

encoders['Manufacturer_target_enc'] = brand_encoding
encoders['Model_target_enc'] = model_encoding

# ========== 7. í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ==========
print("\nğŸ“Š Step 7: í•™ìŠµ ë°ì´í„° ì¤€ë¹„...")

feature_cols = [
    # ê¸°ë³¸
    'Year', 'age', 'age_squared', 'age_cubed',
    
    # ì£¼í–‰ê±°ë¦¬
    'Mileage', 'mileage_log', 'mileage_squared', 'mileage_per_year',
    
    # Target Encoding (í•µì‹¬!)
    'Manufacturer_target_enc', 'Model_target_enc',
    
    # ë¸Œëœë“œ íŠ¹ì„±
    'brand_tier_encoded', 'brand_origin_encoded',
    
    # ì¹´í…Œê³ ë¦¬
    'FuelType_encoded', 'price_segment', 
    'is_diesel', 'is_hybrid', 'is_eco_fuel',
    
    # ìƒíƒœ
    'is_accident_free', 'inspection_score', 'is_premium_condition',
    
    # ì˜µì…˜ (ìˆ˜ì…ì°¨ëŠ” ë§¤ìš° ì¤‘ìš”!)
    *option_cols,
    'option_score', 'option_rate', 'option_weighted', 'is_full_option',
    
    # ì§€ì—­
    'is_metro',
    
    # ìƒí˜¸ì‘ìš©
    'brand_option_interaction', 'model_option_interaction',
    'age_option_interaction', 'age_mileage_interaction',
    'tier_option_interaction'
]

# Train/Test ë¶„ë¦¬
train_df = df[df['is_train'] == 1].copy()
test_df = df[df['is_train'] == 0].copy()

X_train = train_df[feature_cols]
y_train = train_df['Price_log']
X_test = test_df[feature_cols]
y_test = test_df['Price_log']

print(f"âœ“ Feature: {len(feature_cols)}ê°œ")
print(f"âœ“ Train: {len(X_train):,}í–‰")
print(f"âœ“ Test: {len(X_test):,}í–‰")

# ========== 8. ëª¨ë¸ í•™ìŠµ ==========
print("\nğŸ”¥ Step 8: XGBoost í•™ìŠµ (ìˆ˜ì…ì°¨ ìµœì í™”)...")

model = xgb.XGBRegressor(
    n_estimators=1000,
    learning_rate=0.02,
    max_depth=7,              # ìˆ˜ì…ì°¨ëŠ” ë³µì¡ë„ ì•½ê°„ ë†’ì—¬ë„ OK
    min_child_weight=3,
    subsample=0.75,
    colsample_bytree=0.75,
    colsample_bylevel=0.75,
    gamma=0.5,
    reg_alpha=1.5,
    reg_lambda=4.0,
    random_state=42,
    n_jobs=-1,
    verbosity=0
)

model.fit(
    X_train, y_train,
    eval_set=[(X_test, y_test)],
    verbose=100
)

print("\nâœ… í•™ìŠµ ì™„ë£Œ!")

# ========== 9. ëª¨ë¸ í‰ê°€ ==========
print("\n" + "="*80)
print("ğŸ“ˆ Step 9: ëª¨ë¸ í‰ê°€")
print("="*80)

# ë¡œê·¸ â†’ ì›ë˜ ê°€ê²©
y_train_pred_log = model.predict(X_train)
y_test_pred_log = model.predict(X_test)

y_train_pred = np.expm1(y_train_pred_log)
y_test_pred = np.expm1(y_test_pred_log)
y_train_true = np.expm1(y_train)
y_test_true = np.expm1(y_test)

# Train ì„±ëŠ¥
train_mae = mean_absolute_error(y_train_true, y_train_pred)
train_r2 = r2_score(y_train_true, y_train_pred)
train_rmse = np.sqrt(mean_squared_error(y_train_true, y_train_pred))

print(f"\nğŸ”µ Train ì„±ëŠ¥:")
print(f"   MAE:  {train_mae:.2f}ë§Œì›")
print(f"   RMSE: {train_rmse:.2f}ë§Œì›")
print(f"   RÂ²:   {train_r2:.4f}")

# Test ì„±ëŠ¥
test_mae = mean_absolute_error(y_test_true, y_test_pred)
test_r2 = r2_score(y_test_true, y_test_pred)
test_rmse = np.sqrt(mean_squared_error(y_test_true, y_test_pred))

print(f"\nğŸŸ¢ Test ì„±ëŠ¥:")
print(f"   MAE:  {test_mae:.2f}ë§Œì›")
print(f"   RMSE: {test_rmse:.2f}ë§Œì›")
print(f"   RÂ²:   {test_r2:.4f}")

print(f"\nğŸ“Š ê³¼ì í•© ì²´í¬:")
print(f"   Train-Test RÂ² ì°¨ì´: {train_r2 - test_r2:.4f}")
if (train_r2 - test_r2) < 0.10:
    print(f"   âœ… ê³¼ì í•© ì—†ìŒ!")
else:
    print(f"   âš ï¸ ê³¼ì í•© ì¡´ì¬")

# Feature Importance
print(f"\nâ­ Feature Importance (ìƒìœ„ 20ê°œ):")
feature_importance = pd.DataFrame({
    'feature': feature_cols,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

for idx, row in feature_importance.head(20).iterrows():
    print(f"   {row['feature']:40s}: {row['importance']:.4f}")

# ========== 10. ëª¨ë¸ ì €ì¥ ==========
print("\n" + "="*80)
print("ğŸ’¾ Step 10: ëª¨ë¸ ì €ì¥")
print("="*80)

os.makedirs('models', exist_ok=True)

joblib.dump(model, 'models/imported_ultimate.pkl')
joblib.dump(encoders, 'models/imported_ultimate_encoders.pkl')
joblib.dump(feature_cols, 'models/imported_ultimate_features.pkl')

metrics = {
    'train_mae': train_mae, 'train_r2': train_r2, 'train_rmse': train_rmse,
    'test_mae': test_mae, 'test_r2': test_r2, 'test_rmse': test_rmse,
    'n_samples': len(df), 'n_features': len(feature_cols),
    'overfitting_gap': train_r2 - test_r2,
    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
}
joblib.dump(metrics, 'models/imported_ultimate_metrics.pkl')

print(f"\nâœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ")

print("\n" + "="*80)
print("ğŸ‰ ìˆ˜ì…ì°¨ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
print("="*80)
print(f"ğŸ“Š ìµœì¢… ì„±ëŠ¥:")
print(f"   Test RÂ²:  {test_r2:.4f}")
print(f"   Test MAE: {test_mae:.2f}ë§Œì›")
print(f"   Overfit Gap: {train_r2 - test_r2:.4f}")
print(f"   ë°ì´í„°: {len(df):,}ëŒ€")
print("="*80)
