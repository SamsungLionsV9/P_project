"""
Car-Sentix íƒ€ì´ë° ì–´ë“œë°”ì´ì € - ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ê¸°
- ë³´ë°°ë“œë¦¼ ì‹¤ì œ í¬ë¡¤ë§
- ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ëŸ‰ ìˆ˜ì§‘
- í™•ìž¥ëœ í‚¤ì›Œë“œ ì‚¬ì „ ê¸°ë°˜ ê°ì„± ë¶„ì„
- í•œêµ­ì€í–‰/ë„¤ì´ë²„ API ì—°ë™ (API í‚¤ ìžˆì„ ì‹œ)
"""

import requests
import yfinance as yf
import pandas as pd
from datetime import datetime, timedelta
import json
import time
from bs4 import BeautifulSoup
import re
import os
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í‚¤ì›Œë“œ ì‚¬ì „ (ëŒ€í­ í™•ìž¥)
POSITIVE_KEYWORDS = [
    # ì„±ëŠ¥
    "ë¹ ë¥´ë‹¤", "ë¹ ë¦„", "ì¡°ìš©", "ë¶€ë“œëŸ½", "ì•ˆì •ì ", "íƒ„íƒ„", "ê²¬ê³ ",
    # ê°€ê²©
    "ê°€ì„±ë¹„", "ì €ë ´", "í•©ë¦¬ì ", "ì´ë“", "í˜œìž", "ì €ë ´",
    # ë§Œì¡±ë„
    "ì¶”ì²œ", "ë§Œì¡±", "ì¢‹ìŒ", "í›Œë¥­", "ìµœê³ ", "êµ¿", "ì¢‹ì•„", "ê´œì°®",
    # êµ¬ë§¤
    "ê³„ì•½", "êµ¬ìž…", "ê²°ì •", "ì„±ê³µ", "ë“í…œ", "ìƒ€ì–´", "ì§ˆë €",
    # ì˜¨ë¼ì¸ ì€ì–´
    "ê°œê¿€", "í˜œìž", "ê°“ì„±ë¹„", "ì©ë‹¤", "ã„¹ã…‡", "ì¸ì •", "ë ˆì „ë“œ",
    # ë””ìžì¸
    "ì˜ˆì˜", "ë©‹ì§€", "ê³ ê¸‰", "ì„¸ë ¨", "ì´ì˜",
    # íŽ¸ì˜
    "íŽ¸í•˜", "ì¾Œì ", "ë„“", "ì‹¤ìš©",
]

NEGATIVE_KEYWORDS = [
    # ê³ ìž¥
    "ê³ ìž¥", "ê²°í•¨", "í•˜ìž", "ë¬¸ì œ", "ì´ìŠˆ", "ë¶ˆëŸ‰", "íŒŒì†",
    # í’ˆì§ˆ
    "í˜•íŽ¸ì—†", "ì‹¤ë§", "í›„íšŒ", "ìµœì•…", "ë³„ë¡œ", "ì•„ì‰½",
    # ë¦¬ì½œ
    "ë¦¬ì½œ", "íšŒìˆ˜", "ê²°í•¨", "ê¸‰ë°œì§„",
    # ì˜¨ë¼ì¸ ì€ì–´
    "í‰ê¸°ì°¨", "í­íƒ„", "ì§€ë¢°", "ì“°ë ˆê¸°", "ë…¸ë‹µ",
    # ë¹„ìš©
    "ë¹„ì‹¸", "ë¹„ìŒˆ", "ë¹„ìš©", "ë¶€ë‹´",
    # ì†ŒìŒ/ì§„ë™
    "ì‹œë„ëŸ½", "ë–¨ë¦¼", "ì†ŒìŒ", "ì§„ë™",
]

STRONG_POSITIVE = ["ìµœê³ ", "í›Œë¥­", "êµ¿", "ê°œê¿€", "ê°“ì„±ë¹„", "ë ˆì „ë“œ"]
STRONG_NEGATIVE = ["ìµœì•…", "ì“°ë ˆê¸°", "í‰ê¸°ì°¨", "í­íƒ„", "ê¸‰ë°œì§„"]


class RealCommunityCollector:
    """ì‹¤ì œ ì»¤ë®¤ë‹ˆí‹° í¬ë¡¤ë§"""
    
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
        }
    
    def scrape_bobaedream(self, car_model, limit=50):
        """
        ë³´ë°°ë“œë¦¼ ì‹¤ì œ í¬ë¡¤ë§
        
        Args:
            car_model: ì°¨ëŸ‰ ëª¨ë¸ëª…
            limit: ìˆ˜ì§‘í•  ê²Œì‹œê¸€ ìˆ˜
            
        Returns:
            list: [{'title': '...', 'date': '...', 'url': '...'}, ...]
        """
        print(f"ðŸŒ ë³´ë°°ë“œë¦¼ '{car_model}' ê²€ìƒ‰ ì¤‘...")
        
        posts = []
        
        try:
            # ë³´ë°°ë“œë¦¼ ê²€ìƒ‰ URL
            search_url = f"https://www.bobaedream.co.kr/search/?kind=title&txt={car_model}"
            
            response = requests.get(search_url, headers=self.headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ê²Œì‹œê¸€ ëª©ë¡ íŒŒì‹± (ì‹¤ì œ ì„ íƒìžëŠ” ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë”°ë¼ ì¡°ì • í•„ìš”)
            # ë³´ë°°ë“œë¦¼ì€ ë¡œê·¸ì¸ì´ í•„ìš”í•  ìˆ˜ ìžˆìœ¼ë¯€ë¡œ, ëŒ€ì‹  ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ë§Œ íŒŒì‹±
            
            # ê²€ìƒ‰ ê²°ê³¼ ì˜ì—­ ì°¾ê¸°
            search_results = soup.select('.search-result, .list-item, .board-list tr')
            
            if not search_results:
                print(f"  âš ï¸ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ë¡œê·¸ì¸ í•„ìš” or ì„ íƒìž ë³€ê²½)")
                # ëŒ€ì•ˆ: ë„¤ì´ë²„ ë¸”ë¡œê·¸ë¡œ ì „í™˜
                return self.search_naver_blog(car_model, limit)
            
            for idx, item in enumerate(search_results[:limit]):
                try:
                    # ì œëª© ì¶”ì¶œ
                    title_elem = item.select_one('a, .title, td.title')
                    if not title_elem:
                        continue
                    
                    title = title_elem.text.strip()
                    
                    # URL ì¶”ì¶œ
                    url = title_elem.get('href', '')
                    if url and not url.startswith('http'):
                        url = 'https://www.bobaedream.co.kr' + url
                    
                    # ë‚ ì§œ ì¶”ì¶œ
                    date_elem = item.select_one('.date, .time, td.date')
                    date = date_elem.text.strip() if date_elem else datetime.now().strftime('%Y-%m-%d')
                    
                    posts.append({
                        'title': title,
                        'date': date,
                        'url': url,
                        'source': 'ë³´ë°°ë“œë¦¼'
                    })
                    
                except Exception as e:
                    continue
            
            if posts:
                print(f"  âœ“ ë³´ë°°ë“œë¦¼ì—ì„œ {len(posts)}ê°œ ê²Œì‹œê¸€ ìˆ˜ì§‘")
            else:
                print(f"  âš ï¸ ë³´ë°°ë“œë¦¼ íŒŒì‹± ì‹¤íŒ¨, ë„¤ì´ë²„ ë¸”ë¡œê·¸ë¡œ ëŒ€ì²´")
                return self.search_naver_blog(car_model, limit)
            
        except Exception as e:
            print(f"  âœ— ë³´ë°°ë“œë¦¼ ì ‘ì† ì‹¤íŒ¨: {e}")
            print(f"  â†’ ë„¤ì´ë²„ ë¸”ë¡œê·¸ë¡œ ëŒ€ì²´")
            return self.search_naver_blog(car_model, limit)
        
        return posts
    
    def search_naver_blog(self, car_model, limit=50):
        """
        ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ (API ì—†ì´)
        
        Args:
            car_model: ì°¨ëŸ‰ ëª¨ë¸ëª…
            limit: ìˆ˜ì§‘í•  ë¸”ë¡œê·¸ ê°œìˆ˜
            
        Returns:
            list: [{'title': '...', 'date': '...', 'url': '...'}, ...]
        """
        print(f"ðŸ“ ë„¤ì´ë²„ ë¸”ë¡œê·¸ '{car_model}' ê²€ìƒ‰ ì¤‘...")
        
        posts = []
        
        try:
            # ê²€ìƒ‰ ì¿¼ë¦¬: "ëª¨ë¸ëª… ì¤‘ê³ ì°¨" or "ëª¨ë¸ëª… ì‹œìŠ¹ê¸°" or "ëª¨ë¸ëª… ë¦¬ë·°"
            queries = [
                f"{car_model} ì¤‘ê³ ì°¨",
                f"{car_model} ë¦¬ë·°",
                f"{car_model} ì‹œìŠ¹ê¸°"
            ]
            
            for query in queries[:1]:  # ì¼ë‹¨ ì¤‘ê³ ì°¨ë§Œ
                url = f"https://search.naver.com/search.naver?where=blog&query={query}"
                
                response = requests.get(url, headers=self.headers, timeout=10)
                response.raise_for_status()
                
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # ë¸”ë¡œê·¸ ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹±
                blog_items = soup.select('.view_wrap, .total_wrap')
                
                for item in blog_items[:limit]:
                    try:
                        # ì œëª©
                        title_elem = item.select_one('.title_link, .api_txt_lines')
                        if not title_elem:
                            continue
                        
                        title = title_elem.text.strip()
                        
                        # URL
                        url = title_elem.get('href', '')
                        
                        # ë‚ ì§œ
                        date_elem = item.select_one('.sub_time, .sub_txt')
                        date = date_elem.text.strip() if date_elem else ''
                        
                        # ë³¸ë¬¸ ì¼ë¶€
                        desc_elem = item.select_one('.dsc_link, .api_txt_lines.dsc_txt')
                        desc = desc_elem.text.strip() if desc_elem else ''
                        
                        posts.append({
                            'title': title,
                            'description': desc,
                            'date': date,
                            'url': url,
                            'source': 'ë„¤ì´ë²„ë¸”ë¡œê·¸'
                        })
                        
                    except Exception as e:
                        continue
                
                if posts:
                    print(f"  âœ“ ë„¤ì´ë²„ ë¸”ë¡œê·¸ì—ì„œ {len(posts)}ê°œ ê²Œì‹œê¸€ ìˆ˜ì§‘")
                    break
                    
        except Exception as e:
            print(f"  âœ— ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        return posts
    
    def get_naver_blog_count(self, car_model):
        """
        ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ (ê²€ìƒ‰ëŸ‰ ì§€í‘œ)
        
        Returns:
            int: ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜
        """
        print(f"ðŸ”¢ ë„¤ì´ë²„ ë¸”ë¡œê·¸ '{car_model}' ê²€ìƒ‰ëŸ‰ í™•ì¸ ì¤‘...")
        
        try:
            url = f"https://search.naver.com/search.naver?where=blog&query={car_model}+ì¤‘ê³ ì°¨"
            
            response = requests.get(url, headers=self.headers, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ íŒŒì‹±
            # "ë¸”ë¡œê·¸ 1-10 / 15,234ê±´" í˜•íƒœ
            result_text = soup.select_one('.title_desc, .result_stats')
            
            if result_text:
                text = result_text.text
                # ìˆ«ìž ì¶”ì¶œ
                numbers = re.findall(r'[\d,]+', text)
                if numbers:
                    count = int(numbers[-1].replace(',', ''))
                    print(f"  âœ“ ê²€ìƒ‰ ê²°ê³¼: {count:,}ê±´")
                    return count
            
            print(f"  âš ï¸ ê²€ìƒ‰ ê°œìˆ˜ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return 0
            
        except Exception as e:
            print(f"  âœ— ê²€ìƒ‰ëŸ‰ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return 0
    
    def analyze_sentiment_enhanced(self, posts):
        """
        í™•ìž¥ëœ í‚¤ì›Œë“œ ì‚¬ì „ìœ¼ë¡œ ê°ì„± ë¶„ì„
        
        Args:
            posts: ê²Œì‹œê¸€ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            dict: {'positive_ratio': 0.6, 'score': 20, 'trend': 'positive', ...}
        """
        if not posts:
            return {
                'positive_ratio': 0.5,
                'negative_ratio': 0.5,
                'score': 0,
                'trend': 'neutral',
                'total_posts': 0
            }
        
        pos_count = 0
        neg_count = 0
        total_score = 0
        
        for post in posts:
            # ì œëª© + ì„¤ëª… í•©ì¹˜ê¸°
            text = post.get('title', '') + ' ' + post.get('description', '')
            text = text.lower()
            
            # ê°•í•œ ê¸ì • (ê°€ì¤‘ì¹˜ 2)
            strong_pos = sum(2 for w in STRONG_POSITIVE if w in text)
            # ì¼ë°˜ ê¸ì • (ê°€ì¤‘ì¹˜ 1)
            normal_pos = sum(1 for w in POSITIVE_KEYWORDS if w in text)
            
            # ê°•í•œ ë¶€ì • (ê°€ì¤‘ì¹˜ 2)
            strong_neg = sum(2 for w in STRONG_NEGATIVE if w in text)
            # ì¼ë°˜ ë¶€ì • (ê°€ì¤‘ì¹˜ 1)
            normal_neg = sum(1 for w in NEGATIVE_KEYWORDS if w in text)
            
            post_score = (strong_pos + normal_pos) - (strong_neg + normal_neg)
            total_score += post_score
            
            if post_score > 0:
                pos_count += 1
            elif post_score < 0:
                neg_count += 1
        
        total = len(posts)
        pos_ratio = pos_count / total
        neg_ratio = neg_count / total
        neu_ratio = 1 - pos_ratio - neg_ratio
        
        # ì „ì²´ ì ìˆ˜ ì •ê·œí™” (-10 ~ +10)
        avg_score = total_score / total
        normalized_score = max(-10, min(10, avg_score))
        
        # ì¶”ì„¸ íŒë‹¨
        if normalized_score > 3:
            trend = 'positive'
        elif normalized_score < -3:
            trend = 'negative'
        else:
            trend = 'neutral'
        
        result = {
            'positive_ratio': round(pos_ratio, 2),
            'negative_ratio': round(neg_ratio, 2),
            'neutral_ratio': round(neu_ratio, 2),
            'score': round(normalized_score, 1),
            'trend': trend,
            'total_posts': total,
            'keyword_matches': {
                'positive': sum(1 for p in posts if any(w in (p.get('title', '') + p.get('description', '')).lower() for w in POSITIVE_KEYWORDS)),
                'negative': sum(1 for p in posts if any(w in (p.get('title', '') + p.get('description', '')).lower() for w in NEGATIVE_KEYWORDS))
            }
        }
        
        print(f"\nðŸ“Š ê°ì„± ë¶„ì„ ê²°ê³¼:")
        print(f"  ê¸ì •: {result['positive_ratio']:.0%}")
        print(f"  ë¶€ì •: {result['negative_ratio']:.0%}")
        print(f"  ì¤‘ë¦½: {result['neutral_ratio']:.0%}")
        print(f"  ì ìˆ˜: {result['score']:.1f}/10")
        print(f"  ì¶”ì„¸: {result['trend']}")
        
        return result


class RealMacroEconomicCollector:
    """ì‹¤ì œ ê±°ì‹œê²½ì œ ì§€í‘œ ìˆ˜ì§‘"""
    
    def __init__(self, bok_api_key=None):
        """
        Args:
            bok_api_key: í•œêµ­ì€í–‰ Open API í‚¤ (ì„ íƒ)
        """
        self.bok_api_key = bok_api_key or os.getenv('BOK_API_KEY')
    
    def get_interest_rate_real(self):
        """í•œêµ­ì€í–‰ APIë¡œ ì‹¤ì œ ê¸°ì¤€ê¸ˆë¦¬ ì¡°íšŒ"""
        print("ðŸ“Š ê¸°ì¤€ê¸ˆë¦¬ ì¡°íšŒ ì¤‘...")
        
        if not self.bok_api_key:
            print("  âš ï¸ í•œêµ­ì€í–‰ API í‚¤ ì—†ìŒ. ìµœê·¼ ê³µê°œ ì •ë³´ë¡œ ëŒ€ì²´")
            # ìµœê·¼ ê³µê°œëœ ê¸ˆë¦¬ ì •ë³´ (2024ë…„ 11ì›” ê¸°ì¤€)
            return {
                'rate': 3.25,
                'date': '2024-11-01',
                'trend': 'stable',
                'source': 'ìµœê·¼ ê³µê°œ ì •ë³´ (API í‚¤ í•„ìš”)',
                'note': 'BOK_API_KEY í™˜ê²½ë³€ìˆ˜ ì„¤ì • í•„ìš”'
            }
        
        try:
            # í•œêµ­ì€í–‰ Open API
            # í†µê³„ì½”ë“œ: 722Y001 (ê¸°ì¤€ê¸ˆë¦¬)
            url = f"https://ecos.bok.or.kr/api/StatisticSearch/{self.bok_api_key}/json/kr/1/10/722Y001/D"
            
            # ìµœê·¼ 30ì¼
            end_date = datetime.now().strftime('%Y%m%d')
            start_date = (datetime.now() - timedelta(days=30)).strftime('%Y%m%d')
            url += f"/{start_date}/{end_date}/0101000"
            
            response = requests.get(url, timeout=10)
            data = response.json()
            
            if 'StatisticSearch' in data and 'row' in data['StatisticSearch']:
                rows = data['StatisticSearch']['row']
                
                # ìµœì‹  ê¸ˆë¦¬
                latest = rows[0]
                current_rate = float(latest['DATA_VALUE'])
                
                # ì¶”ì„¸ ê³„ì‚° (ì²« ë°ì´í„°ì™€ ë¹„êµ)
                if len(rows) > 1:
                    previous_rate = float(rows[-1]['DATA_VALUE'])
                    if current_rate > previous_rate:
                        trend = 'up'
                    elif current_rate < previous_rate:
                        trend = 'down'
                    else:
                        trend = 'stable'
                else:
                    trend = 'stable'
                    previous_rate = current_rate
                
                result = {
                    'rate': current_rate,
                    'date': latest['TIME'],
                    'trend': trend,
                    'previous_rate': previous_rate,
                    'change': current_rate - previous_rate,
                    'source': 'í•œêµ­ì€í–‰ Open API'
                }
                
                print(f"  âœ“ í˜„ìž¬ ê¸ˆë¦¬: {current_rate}%")
                print(f"  âœ“ ì¶”ì„¸: {trend}")
                
                return result
            else:
                raise ValueError("API ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜")
                
        except Exception as e:
            print(f"  âœ— API ì¡°íšŒ ì‹¤íŒ¨: {e}")
            # ìµœê·¼ ê³µê°œ ì •ë³´ë¡œ fallback
            return {
                'rate': 3.25,
                'date': datetime.now().strftime('%Y-%m-%d'),
                'trend': 'stable',
                'source': 'fallback'
            }
    
    def get_oil_price(self):
        """yfinanceë¡œ ì‹¤ì œ ìœ ê°€ ì¡°íšŒ (WTI)"""
        print("ðŸ›¢ï¸ êµ­ì œ ìœ ê°€ ì¡°íšŒ ì¤‘...")
        
        try:
            oil = yf.Ticker("CL=F")
            history = oil.history(period="5d")
            
            if not history.empty:
                current_price = history['Close'].iloc[-1]
                previous_price = history['Close'].iloc[0]
                
                trend = 'up' if current_price > previous_price * 1.02 else \
                        'down' if current_price < previous_price * 0.98 else 'stable'
                
                result = {
                    'price': round(current_price, 2),
                    'date': datetime.now().strftime('%Y-%m-%d'),
                    'trend': trend,
                    'previous_price': round(previous_price, 2),
                    'change': round(current_price - previous_price, 2),
                    'change_pct': round((current_price - previous_price) / previous_price * 100, 2),
                    'source': 'Yahoo Finance (WTI)'
                }
                
                print(f"  âœ“ í˜„ìž¬ ìœ ê°€: ${current_price:.2f}")
                print(f"  âœ“ ì¶”ì„¸: {trend} ({result['change_pct']:+.1f}%)")
                
                return result
            else:
                raise ValueError("ìœ ê°€ ë°ì´í„° ì—†ìŒ")
                
        except Exception as e:
            print(f"  âœ— ìœ ê°€ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                'price': 75.0,
                'date': datetime.now().strftime('%Y-%m-%d'),
                'trend': 'stable',
                'source': 'default'
            }
    
    def get_exchange_rate(self):
        """yfinanceë¡œ ì‹¤ì œ í™˜ìœ¨ ì¡°íšŒ (USD/KRW)"""
        print("ðŸ’± í™˜ìœ¨ ì¡°íšŒ ì¤‘...")
        
        try:
            krw = yf.Ticker("KRW=X")
            history = krw.history(period="5d")
            
            if not history.empty:
                current_rate = history['Close'].iloc[-1]
                previous_rate = history['Close'].iloc[0]
                
                trend = 'up' if current_rate > previous_rate * 1.01 else \
                        'down' if current_rate < previous_rate * 0.99 else 'stable'
                
                result = {
                    'rate': round(current_rate, 2),
                    'date': datetime.now().strftime('%Y-%m-%d'),
                    'trend': trend,
                    'previous_rate': round(previous_rate, 2),
                    'change': round(current_rate - previous_rate, 2),
                    'source': 'Yahoo Finance'
                }
                
                print(f"  âœ“ í˜„ìž¬ í™˜ìœ¨: {current_rate:.2f}ì›")
                print(f"  âœ“ ì¶”ì„¸: {trend}")
                
                return result
            else:
                raise ValueError("í™˜ìœ¨ ë°ì´í„° ì—†ìŒ")
                
        except Exception as e:
            print(f"  âœ— í™˜ìœ¨ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                'rate': 1300.0,
                'date': datetime.now().strftime('%Y-%m-%d'),
                'trend': 'stable',
                'source': 'default'
            }
    
    def get_all_indicators(self):
        """ëª¨ë“  ê±°ì‹œê²½ì œ ì§€í‘œ ìˆ˜ì§‘"""
        return {
            'interest_rate': self.get_interest_rate_real(),
            'oil_price': self.get_oil_price(),
            'exchange_rate': self.get_exchange_rate(),
            'collected_at': datetime.now().isoformat()
        }


# í†µí•© í•¨ìˆ˜
def collect_real_data(car_model, bok_api_key=None):
    """
    ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ (ì‹œë®¬ë ˆì´ì…˜ ì—†ìŒ)
    
    Args:
        car_model: ì°¨ëŸ‰ ëª¨ë¸ëª…
        bok_api_key: í•œêµ­ì€í–‰ API í‚¤ (ì„ íƒ)
        
    Returns:
        dict: ëª¨ë“  ìˆ˜ì§‘ ë°ì´í„°
    """
    print("=" * 80)
    print(f"ðŸ“¡ '{car_model}' ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ ì‹œìž‘")
    print("=" * 80)
    
    # 1. ê±°ì‹œê²½ì œ ì§€í‘œ
    macro = RealMacroEconomicCollector(bok_api_key)
    macro_data = macro.get_all_indicators()
    
    print()
    
    # 2. ì»¤ë®¤ë‹ˆí‹° ë°ì´í„°
    community = RealCommunityCollector()
    
    # ë³´ë°°ë“œë¦¼ ë˜ëŠ” ë„¤ì´ë²„ ë¸”ë¡œê·¸
    posts = community.scrape_bobaedream(car_model, limit=50)
    
    # ê°ì„± ë¶„ì„
    sentiment_data = community.analyze_sentiment_enhanced(posts)
    
    print()
    
    # 3. ê²€ìƒ‰ëŸ‰ (ì¶”ê°€)
    blog_count = community.get_naver_blog_count(car_model)
    
    print()
    
    # 4. ì‹ ì°¨ ì¼ì • (ê¸°ì¡´ DB í™œìš©)
    from data_collectors import NewCarScheduleManager
    schedule = NewCarScheduleManager()
    schedule_data = schedule.check_upcoming_release(car_model)
    
    print()
    print("=" * 80)
    print("âœ… ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
    print("=" * 80)
    
    return {
        'car_model': car_model,
        'macro': macro_data,
        'community': {
            'posts': posts,
            'sentiment': sentiment_data,
            'blog_count': blog_count
        },
        'schedule': schedule_data,
        'collected_at': datetime.now().isoformat()
    }


if __name__ == "__main__":
    print("=" * 80)
    print("Car-Sentix ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ê¸° í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    # í…ŒìŠ¤íŠ¸ ì°¨ëŸ‰
    test_model = "ê·¸ëžœì €"
    
    # BOK API í‚¤ (í™˜ê²½ë³€ìˆ˜ì—ì„œ ì½ê¸°, ì—†ìœ¼ë©´ None)
    bok_key = os.getenv('BOK_API_KEY')
    
    if bok_key:
        print(f"âœ“ í•œêµ­ì€í–‰ API í‚¤ ê°ì§€ë¨")
    else:
        print(f"âš ï¸ í•œêµ­ì€í–‰ API í‚¤ ì—†ìŒ (BOK_API_KEY í™˜ê²½ë³€ìˆ˜ ì„¤ì •)")
        print(f"   â†’ ìµœê·¼ ê³µê°œ ì •ë³´ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤")
    
    print()
    
    # ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘
    data = collect_real_data(test_model, bok_key)
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 80)
    print("ðŸ“Š ìˆ˜ì§‘ ë°ì´í„° ìš”ì•½")
    print("=" * 80)
    
    print(f"\nðŸš— ì°¨ëŸ‰: {data['car_model']}")
    
    print(f"\nðŸ“Š ê±°ì‹œê²½ì œ:")
    print(f"  - ê¸ˆë¦¬: {data['macro']['interest_rate']['rate']}% ({data['macro']['interest_rate']['trend']})")
    print(f"  - ìœ ê°€: ${data['macro']['oil_price']['price']:.2f} ({data['macro']['oil_price']['trend']})")
    print(f"  - í™˜ìœ¨: {data['macro']['exchange_rate']['rate']:.2f}ì› ({data['macro']['exchange_rate']['trend']})")
    
    print(f"\nðŸ’¬ ì»¤ë®¤ë‹ˆí‹°:")
    print(f"  - ìˆ˜ì§‘ ê²Œì‹œê¸€: {data['community']['sentiment']['total_posts']}ê°œ")
    print(f"  - ë¸”ë¡œê·¸ ê²€ìƒ‰ëŸ‰: {data['community']['blog_count']:,}ê±´")
    print(f"  - ê¸ì • ë¹„ìœ¨: {data['community']['sentiment']['positive_ratio']:.0%}")
    print(f"  - ë¶€ì • ë¹„ìœ¨: {data['community']['sentiment']['negative_ratio']:.0%}")
    print(f"  - ê°ì„± ì ìˆ˜: {data['community']['sentiment']['score']:.1f}/10")
    print(f"  - ì¶”ì„¸: {data['community']['sentiment']['trend']}")
    
    print(f"\nðŸš— ì‹ ì°¨ ì¶œì‹œ:")
    if data['schedule']['has_upcoming']:
        print(f"  - ì˜ˆì • ëª¨ë¸: {data['schedule']['new_model']}")
        print(f"  - ì¶œì‹œì¼: {data['schedule']['release_date']} ({data['schedule']['months_until']:.1f}ê°œì›” í›„)")
        print(f"  - ì˜í–¥ë„: {data['schedule']['impact']}")
    else:
        print(f"  - ì˜ˆì • ì—†ìŒ")
    
    # JSON ì €ìž¥
    output_file = f'real_timing_data_{test_model}_{datetime.now().strftime("%Y%m%d_%H%M")}.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        # postsëŠ” ë„ˆë¬´ í¬ë¯€ë¡œ ì œì™¸í•˜ê³  ìš”ì•½ë§Œ ì €ìž¥
        save_data = data.copy()
        save_data['community']['posts_summary'] = {
            'count': len(data['community']['posts']),
            'sample_titles': [p['title'] for p in data['community']['posts'][:5]]
        }
        del save_data['community']['posts']
        
        json.dump(save_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nðŸ’¾ ë°ì´í„° ì €ìž¥: {output_file}")
    
    print("\n" + "=" * 80)
    print("ðŸŽ¯ ë‹¤ìŒ ë‹¨ê³„:")
    print("=" * 80)
    print("\n1. â³ í•œêµ­ì€í–‰ API í‚¤ ë°œê¸‰ (https://ecos.bok.or.kr)")
    print("   â†’ BOK_API_KEY í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •")
    print("\n2. âœ… ì»¤ë®¤ë‹ˆí‹° í¬ë¡¤ë§ ì •ìƒ ìž‘ë™")
    print("   â†’ ë³´ë°°ë“œë¦¼ or ë„¤ì´ë²„ ë¸”ë¡œê·¸")
    print("\n3. âœ… ê°ì„± ë¶„ì„ í™•ìž¥ í‚¤ì›Œë“œ ì ìš©")
    print(f"   â†’ {len(POSITIVE_KEYWORDS)}ê°œ ê¸ì •, {len(NEGATIVE_KEYWORDS)}ê°œ ë¶€ì • í‚¤ì›Œë“œ")
    print("\n4. â³ ë„¤ì´ë²„ ë°ì´í„°ëž© API (ì„ íƒ)")
    print("   â†’ ê²€ìƒ‰ íŠ¸ë Œë“œ ì •í™•ë„ í–¥ìƒ")
