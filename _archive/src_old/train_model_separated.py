"""
êµ­ì‚°ì°¨/ìˆ˜ì…ì°¨ ë¶„ë¦¬ í•™ìŠµ ì‹œìŠ¤í…œ
- ê° ì°¨ëŸ‰ ìœ í˜•ë³„ ìµœì í™”ëœ ëª¨ë¸ ìƒì„±
- ê³ ê°€ ìˆ˜ì…ì°¨ë„ ì´ìƒì¹˜ ì œê±° ì—†ì´ í•™ìŠµ
"""
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from xgboost import XGBRegressor
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
import os

# Set plot style
sns.set(style="whitegrid")
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

def create_features(df, car_type='domestic'):
    """
    ì°¨ëŸ‰ ìœ í˜•ë³„ ìµœì í™”ëœ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
    
    Args:
        df: DataFrame
        car_type: 'domestic' or 'imported'
    """
    print(f"  ğŸ”§ {car_type.upper()} í”¼ì²˜ ìƒì„± ì¤‘...")
    
    current_year = 2025
    df['age'] = current_year - df['year']
    
    # ê³µí†µ í”¼ì²˜
    df['mileage_per_year'] = df['mileage'] / (df['age'] + 1)
    df['is_low_mileage'] = (df['mileage'] < 30000).astype(int)
    
    # ì—°ë ¹ ê·¸ë£¹
    df['age_group'] = pd.cut(df['age'], 
                              bins=[-1, 1, 3, 5, 10, 100], 
                              labels=['new', 'semi_new', 'used', 'old', 'very_old'])
    
    # ë¸Œëœë“œ-ì—°ë£Œ ì¡°í•©
    df['brand_fuel'] = df['brand'] + '_' + df['fuel']
    
    # ëª¨ë¸ ì¸ê¸°ë„
    model_counts = df['model_name'].value_counts()
    df['model_popularity'] = df['model_name'].map(model_counts)
    df['model_popularity_log'] = np.log1p(df['model_popularity'])
    
    # ì°¨ëŸ‰ ìœ í˜•ë³„ íŠ¹í™” í”¼ì²˜
    if car_type == 'domestic':
        # êµ­ì‚°ì°¨: ì£¼í–‰ê±°ë¦¬ì™€ ì—°ì‹ì— ë” ë¯¼ê°
        df['is_high_mileage'] = (df['mileage'] > 150000).astype(int)
        df['age_mileage_interaction'] = df['age'] * np.log1p(df['mileage'])
        
        # ê³ ê¸‰ ë¸Œëœë“œ êµ¬ë¶„ (ì œë„¤ì‹œìŠ¤)
        df['is_premium_domestic'] = (df['brand'] == 'ì œë„¤ì‹œìŠ¤').astype(int)
        
        # ì œì¡°ì‚¬ë³„ í‰ê·  ê°€ê²© (ì‹œì¥ í¬ì§€ì…”ë‹)
        brand_price_mean = df.groupby('brand')['price'].transform('mean')
        df['brand_price_tier'] = pd.cut(brand_price_mean, bins=3, labels=['budget', 'mid', 'premium'])
        
    elif car_type == 'imported':
        # ìˆ˜ì…ì°¨: ë¸Œëœë“œ í”„ë¦¬ë¯¸ì—„ì´ í•µì‹¬
        luxury_brands = ['ë²¤ì¸ ', 'BMW', 'ì•„ìš°ë””', 'ë ‰ì„œìŠ¤', 'í¬ë¥´ì‰', 
                        'í˜ë¼ë¦¬', 'ëŒë³´ë¥´ê¸°ë‹ˆ', 'ë²¤í‹€ë¦¬', 'ë¡¤ìŠ¤ë¡œì´ìŠ¤', 'ë§¥ë¼ë Œ',
                        'ë§ˆì„¸ë¼í‹°', 'ì• ìŠ¤í„´ë§ˆí‹´']
        df['is_luxury'] = df['brand'].isin(luxury_brands).astype(int)
        
        # ê³ ê°€ ì°¨ëŸ‰ êµ¬ë¶„ (5000ë§Œì› ì´ìƒ)
        df['is_ultra_premium'] = (df['price'] > 5000).astype(int)
        
        # ë¸Œëœë“œë³„ í‰ê·  ê°€ê²© (ë¸Œëœë“œ ê°€ì¹˜)
        brand_price_mean = df.groupby('brand')['price'].transform('mean')
        df['brand_value'] = brand_price_mean
        df['price_vs_brand_avg'] = df['price'] / (brand_price_mean + 1)
        
        # í¬ì†Œì„± (ëª¨ë¸ ê°œìˆ˜ê°€ ì ì„ìˆ˜ë¡ í¬ì†Œ)
        df['model_rarity'] = 1 / (df['model_popularity'] + 1)
    
    # ì „ê¸°/í•˜ì´ë¸Œë¦¬ë“œ
    df['is_eco'] = df['fuel'].str.contains('ì „ê¸°|í•˜ì´ë¸Œë¦¬ë“œ', na=False).astype(int)
    
    # ê°€ê²© ë¡œê·¸ ë³€í™˜ (íƒ€ê²Ÿ)
    df['log_price'] = np.log1p(df['price'])
    
    print(f"     âœ“ ìƒì„±ëœ í”¼ì²˜ ìˆ˜: {len([c for c in df.columns if c not in ['price', 'log_price']])}")
    
    return df

def train_single_model(df, car_type, model_path):
    """
    ë‹¨ì¼ ì°¨ëŸ‰ ìœ í˜• ëª¨ë¸ í•™ìŠµ
    
    Args:
        df: DataFrame (í•´ë‹¹ ì°¨ëŸ‰ ìœ í˜•ë§Œ)
        car_type: 'domestic' or 'imported'
        model_path: ì €ì¥ ê²½ë¡œ
    """
    print(f"\n{'='*70}")
    print(f"  ğŸ“š {car_type.upper()} MODEL TRAINING")
    print(f"{'='*70}")
    print(f"  ë°ì´í„° í¬ê¸°: {len(df):,}ê±´")
    
    # í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
    df = create_features(df, car_type)
    
    # ì´ìƒì¹˜ ì œê±° ì „ëµ
    if car_type == 'domestic':
        # êµ­ì‚°ì°¨: ëª…í™•í•œ ì˜¤ë¥˜ ë°ì´í„°ë§Œ ì œê±°
        # ì œë„¤ì‹œìŠ¤ G90 ì‹ ì°¨ê°€ 1ì–µ ì´ìƒì´ë¯€ë¡œ, 2ì–µ ì´í•˜ëŠ” ì •ìƒìœ¼ë¡œ ê°„ì£¼
        price_threshold = 20000  # 2ì–µì›
        initial_count = len(df)
        
        # ê·¹ë‹¨ì  ì´ìƒì¹˜ë§Œ ì œê±° (ëª…ë°±í•œ ì…ë ¥ ì˜¤ë¥˜)
        df = df[df['price'] <= price_threshold]
        
        # ì¶”ê°€: ê°€ê²©ì´ ë„ˆë¬´ ë‚®ì€ ê²ƒë„ ì œê±° (100ë§Œì› ì´í•˜ëŠ” ì˜¤ë¥˜ì¼ ê°€ëŠ¥ì„±)
        df = df[df['price'] >= 100]
        
        removed = initial_count - len(df)
        print(f"  ğŸ§¹ ê·¹ë‹¨ ì´ìƒì¹˜ ì œê±°: {removed:,}ê±´ (100ë§Œì› ë¯¸ë§Œ ë˜ëŠ” {price_threshold:,}ë§Œì› ì´ˆê³¼)")
        print(f"  â„¹ï¸  ì œë„¤ì‹œìŠ¤ ë“± ê³ ê¸‰ êµ­ì‚°ì°¨ í¬í•¨ (ì •ìƒ ë°ì´í„°)")
    else:
        # ìˆ˜ì…ì°¨: ì´ìƒì¹˜ ì œê±° ì•ˆ í•¨ (ê³ ê°€ ì°¨ëŸ‰ë„ ìœ íš¨ ë°ì´í„°)
        print(f"  â„¹ï¸  ìˆ˜ì…ì°¨ëŠ” ì´ìƒì¹˜ ì œê±° ì—†ìŒ (ê³ ê°€ ì°¨ëŸ‰ í¬í•¨)")
    
    print(f"  ìµœì¢… ë°ì´í„°: {len(df):,}ê±´")
    print(f"  ê°€ê²© ë²”ìœ„: {df['price'].min():.0f}ë§Œì› ~ {df['price'].max():.0f}ë§Œì›")
    
    # Train/Test split
    categorical_features = ['brand', 'model_name', 'fuel', 'age_group', 'brand_fuel']
    if car_type == 'domestic' and 'brand_price_tier' in df.columns:
        categorical_features.append('brand_price_tier')
    
    # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
    categorical_features = [f for f in categorical_features if f in df.columns]
    
    numerical_features = ['age', 'mileage', 'mileage_per_year', 
                         'is_low_mileage', 'model_popularity_log', 'is_eco']
    
    # ì°¨ëŸ‰ ìœ í˜•ë³„ ì¶”ê°€ í”¼ì²˜
    if car_type == 'domestic' and 'is_high_mileage' in df.columns:
        numerical_features.extend(['is_high_mileage', 'age_mileage_interaction', 'is_premium_domestic'])
    elif car_type == 'imported' and 'is_luxury' in df.columns:
        numerical_features.extend(['is_luxury', 'is_ultra_premium', 'brand_value', 
                                   'price_vs_brand_avg', 'model_rarity'])
    
    # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
    numerical_features = [f for f in numerical_features if f in df.columns]
    
    feature_cols = categorical_features + numerical_features
    X = df[feature_cols]
    y = df['log_price']
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    print(f"\n  ğŸ“Š Train: {len(X_train):,} | Test: {len(X_test):,}")
    
    # Preprocessing pipeline
    preprocessor = ColumnTransformer(
        transformers=[
            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),
            ('num', 'passthrough', numerical_features)
        ]
    )
    
    # XGBoost í•˜ì´í¼íŒŒë¼ë¯¸í„° (ì°¨ëŸ‰ ìœ í˜•ë³„ ìµœì í™”)
    if car_type == 'domestic':
        xgb_params = {
            'n_estimators': 1000,
            'learning_rate': 0.05,
            'max_depth': 7,
            'min_child_weight': 3,
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'objective': 'reg:squarederror',
            'random_state': 42,
            'n_jobs': -1
        }
    else:  # imported
        xgb_params = {
            'n_estimators': 1500,  # ë” ë§ì€ íŠ¸ë¦¬
            'learning_rate': 0.03,  # ë” ëŠë¦° í•™ìŠµ
            'max_depth': 8,  # ë” ê¹Šì€ íŠ¸ë¦¬ (ë³µì¡í•œ íŒ¨í„´)
            'min_child_weight': 1,  # ë” ì„¸ë°€í•œ ë¶„í• 
            'subsample': 0.9,
            'colsample_bytree': 0.9,
            'objective': 'reg:squarederror',
            'random_state': 42,
            'n_jobs': -1
        }
    
    # Create pipeline
    pipeline = Pipeline([
        ('preprocessor', preprocessor),
        ('model', XGBRegressor(**xgb_params))
    ])
    
    # Train
    print(f"\n  ğŸš€ ëª¨ë¸ í•™ìŠµ ì¤‘...")
    pipeline.fit(X_train, y_train)
    
    # Predictions
    y_train_pred = pipeline.predict(X_train)
    y_test_pred = pipeline.predict(X_test)
    
    # Convert back from log
    y_train_actual = np.expm1(y_train)
    y_test_actual = np.expm1(y_test)
    y_train_pred_actual = np.expm1(y_train_pred)
    y_test_pred_actual = np.expm1(y_test_pred)
    
    # Metrics
    train_mae = mean_absolute_error(y_train_actual, y_train_pred_actual)
    test_mae = mean_absolute_error(y_test_actual, y_test_pred_actual)
    train_r2 = r2_score(y_train_actual, y_train_pred_actual)
    test_r2 = r2_score(y_test_actual, y_test_pred_actual)
    
    # MAPE
    train_mape = np.mean(np.abs((y_train_actual - y_train_pred_actual) / y_train_actual)) * 100
    test_mape = np.mean(np.abs((y_test_actual - y_test_pred_actual) / y_test_actual)) * 100
    
    print(f"\n  ğŸ“ˆ ì„±ëŠ¥ ì§€í‘œ:")
    print(f"     Train MAE: {train_mae:.0f}ë§Œì› | MAPE: {train_mape:.2f}%")
    print(f"     Test MAE:  {test_mae:.0f}ë§Œì› | MAPE: {test_mape:.2f}%")
    print(f"     Train RÂ²:  {train_r2:.4f}")
    print(f"     Test RÂ²:   {test_r2:.4f}")
    
    # Save model
    os.makedirs(os.path.dirname(model_path), exist_ok=True)
    joblib.dump(pipeline, model_path)
    print(f"\n  âœ… ëª¨ë¸ ì €ì¥: {model_path}")
    
    # Save metrics
    metrics = {
        'car_type': car_type,
        'data_count': len(df),
        'train_mae': train_mae,
        'test_mae': test_mae,
        'train_r2': train_r2,
        'test_r2': test_r2,
        'train_mape': train_mape,
        'test_mape': test_mape,
        'price_min': df['price'].min(),
        'price_max': df['price'].max(),
        'price_mean': df['price'].mean()
    }
    
    return pipeline, metrics, (X_test, y_test_actual, y_test_pred_actual)

def train_separated_models(combined_data_path='../data/processed_encar_combined.csv'):
    """
    êµ­ì‚°ì°¨/ìˆ˜ì…ì°¨ ë¶„ë¦¬ í•™ìŠµ ë©”ì¸ í•¨ìˆ˜
    """
    print("\n" + "="*70)
    print("  ğŸš— êµ­ì‚°ì°¨/ìˆ˜ì…ì°¨ ë¶„ë¦¬ í•™ìŠµ ì‹œìŠ¤í…œ")
    print("="*70)
    
    # Load data
    print("\nğŸ“‚ í†µí•© ë°ì´í„° ë¡œë”©...")
    df = pd.read_csv(combined_data_path)
    print(f"   ì „ì²´ ë°ì´í„°: {len(df):,}ê±´")
    
    # Split by car type
    df_domestic = df[df['car_type'] == 'Domestic'].copy()
    df_imported = df[df['car_type'] == 'Imported'].copy()
    
    print(f"   êµ­ì‚°ì°¨: {len(df_domestic):,}ê±´")
    print(f"   ìˆ˜ì…ì°¨: {len(df_imported):,}ê±´")
    
    # Train domestic model
    domestic_model, domestic_metrics, domestic_test = train_single_model(
        df_domestic, 
        'domestic',
        '../models/domestic_car_price_model.pkl'
    )
    
    # Train imported model
    imported_model, imported_metrics, imported_test = train_single_model(
        df_imported,
        'imported', 
        '../models/imported_car_price_model.pkl'
    )
    
    # Summary comparison
    print("\n" + "="*70)
    print("  ğŸ“Š ëª¨ë¸ ë¹„êµ ìš”ì•½")
    print("="*70)
    
    comparison = pd.DataFrame([domestic_metrics, imported_metrics])
    comparison = comparison[['car_type', 'data_count', 'test_mae', 'test_mape', 'test_r2', 'price_mean', 'price_max']]
    comparison.columns = ['ì°¨ëŸ‰ìœ í˜•', 'ë°ì´í„°ìˆ˜', 'MAE(ë§Œì›)', 'MAPE(%)', 'RÂ²', 'í‰ê· ê°€ê²©', 'ìµœê³ ê°€ê²©']
    print("\n" + comparison.to_string(index=False))
    
    # Save comparison
    comparison.to_csv('../models/separated_models_comparison.csv', index=False, encoding='utf-8-sig')
    print(f"\n  âœ… ë¹„êµí‘œ ì €ì¥: ../models/separated_models_comparison.csv")
    
    print("\n" + "="*70)
    print("  ğŸ‰ ë¶„ë¦¬ í•™ìŠµ ì™„ë£Œ!")
    print("="*70)
    print("\n  ğŸ“ ìƒì„±ëœ ëª¨ë¸:")
    print("     1. domestic_car_price_model.pkl (êµ­ì‚°ì°¨)")
    print("     2. imported_car_price_model.pkl (ìˆ˜ì…ì°¨)")
    print("     3. separated_models_comparison.csv (ë¹„êµí‘œ)")

if __name__ == "__main__":
    train_separated_models()
