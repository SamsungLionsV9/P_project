"""
ì¼ë°˜ êµ­ì‚°ì°¨ ëª¨ë¸ ê°œì„  ë²„ì „
- ëª¨ë¸ëª… ì„¸ëŒ€ íŒŒì‹±
- íŠ¸ë¦¼ ì •ë³´ í™œìš©
- ì¸ê¸° ëª¨ë¸ íŠ¹í™”
- ì£¼í–‰ê±°ë¦¬/ì—°ì‹ ì„¸ë¶„í™”
"""
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from xgboost import XGBRegressor
import joblib
import os
import re

def extract_generation(model_name):
    """ëª¨ë¸ëª…ì—ì„œ ì„¸ëŒ€ ì •ë³´ ì¶”ì¶œ"""
    model_str = str(model_name)
    
    # ê·¸ëœì € ì„¸ëŒ€
    if 'ê·¸ëœì €' in model_str:
        if 'GN7' in model_str or 'ë” ë‰´ ê·¸ëœì €' in model_str:
            return 'GN7'
        elif 'IG' in model_str:
            return 'IG'
        elif 'HG' in model_str:
            return 'HG'
    
    # ì˜ë‚˜íƒ€ ì„¸ëŒ€
    elif 'ì˜ë‚˜íƒ€' in model_str:
        if 'DN8' in model_str or 'ë”” ì—£ì§€' in model_str:
            return 'DN8'
        elif 'LF' in model_str:
            return 'LF'
        elif 'YF' in model_str:
            return 'YF'
    
    # ì‹¼íƒ€í˜ ì„¸ëŒ€
    elif 'ì‹¼íƒ€í˜' in model_str:
        if 'MX5' in model_str or '5ì„¸ëŒ€' in model_str:
            return 'MX5'
        elif 'TM' in model_str or '4ì„¸ëŒ€' in model_str:
            return 'TM'
        elif 'DM' in model_str or '3ì„¸ëŒ€' in model_str:
            return 'DM'
    
    # íˆ¬ì‹¼ ì„¸ëŒ€
    elif 'íˆ¬ì‹¼' in model_str:
        if 'NX4' in model_str or '4ì„¸ëŒ€' in model_str:
            return 'NX4'
        elif 'TL' in model_str or '3ì„¸ëŒ€' in model_str:
            return 'TL'
    
    # K5 ì„¸ëŒ€
    elif 'K5' in model_str:
        if 'DL3' in model_str or '3ì„¸ëŒ€' in model_str:
            return 'DL3'
        elif 'JF' in model_str or '2ì„¸ëŒ€' in model_str:
            return 'JF'
    
    # ì˜ë Œí†  ì„¸ëŒ€
    elif 'ì˜ë Œí† ' in model_str:
        if '4ì„¸ëŒ€' in model_str or 'MQ4' in model_str:
            return 'MQ4'
        elif '3ì„¸ëŒ€' in model_str or 'UM' in model_str:
            return 'UM'
    
    # ì¹´ë‹ˆë°œ ì„¸ëŒ€
    elif 'ì¹´ë‹ˆë°œ' in model_str:
        if '4ì„¸ëŒ€' in model_str or 'KA4' in model_str:
            return 'KA4'
        elif '3ì„¸ëŒ€' in model_str:
            return 'KA3'
    
    return 'unknown'

def extract_trim_features(model_name, fuel):
    """íŠ¸ë¦¼ íŠ¹ì„± ì¶”ì¶œ"""
    model_str = str(model_name).lower()
    
    features = {}
    
    # í•˜ì´ë¸Œë¦¬ë“œ/ì „ê¸° (ì—°ë£Œì™€ êµì°¨ ê²€ì¦)
    features['is_hybrid'] = 1 if ('í•˜ì´ë¸Œë¦¬ë“œ' in model_str or 'í•˜ì´ë¸Œë¦¬ë“œ' in fuel) else 0
    features['is_electric'] = 1 if ('ì „ê¸°' in model_str or 'ì „ê¸°' in fuel) else 0
    
    # ê³ ê¸‰ íŠ¸ë¦¼
    features['is_premium_trim'] = 1 if any(x in model_str for x in ['í”„ë ˆìŠ¤í‹°ì§€', 'ì‹œê·¸ë‹ˆì²˜', 'ë…¸ë¸”ë ˆìŠ¤', 'ìµìŠ¤í´ë£¨ì‹œë¸Œ']) else 0
    
    # N ë¼ì¸ / ìŠ¤í¬ì¸ 
    features['is_sport'] = 1 if any(x in model_str for x in ['në¼ì¸', 'n-ë¼ì¸', 'ìŠ¤í¬ì¸ ']) else 0
    
    # ë¡±ë°”ë”” / 7ì¸ìŠ¹
    features['is_large'] = 1 if any(x in model_str for x in ['ë¡±ë°”ë””', '7ì¸ìŠ¹', '9ì¸ìŠ¹', '11ì¸ìŠ¹']) else 0
    
    return features

def create_improved_features(df):
    """ê°œì„ ëœ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§"""
    print("  ğŸ”§ ê°œì„ ëœ í”¼ì²˜ ìƒì„± ì¤‘...")
    
    current_year = 2025
    df['age'] = current_year - df['year']
    
    # ê¸°ë³¸ í”¼ì²˜
    df['mileage_per_year'] = df['mileage'] / (df['age'] + 1)
    df['is_low_mileage'] = (df['mileage'] < 30000).astype(int)
    df['is_high_mileage'] = (df['mileage'] > 150000).astype(int)
    
    # ì—°ë ¹ ê·¸ë£¹ (ë” ì„¸ë¶„í™”)
    df['age_group'] = pd.cut(df['age'], 
                              bins=[-1, 1, 2, 3, 5, 7, 100], 
                              labels=['1ë…„', '2ë…„', '3ë…„', '3-5ë…„', '5-7ë…„', '7ë…„+'])
    
    # ì£¼í–‰ê±°ë¦¬ ê·¸ë£¹
    df['mileage_group'] = pd.cut(df['mileage'],
                                  bins=[-1, 30000, 60000, 100000, 150000, 999999],
                                  labels=['3ë§Œì´í•˜', '3-6ë§Œ', '6-10ë§Œ', '10-15ë§Œ', '15ë§Œ+'])
    
    # ì„¸ëŒ€ ì •ë³´ ì¶”ì¶œ
    df['generation'] = df['model_name'].apply(extract_generation)
    
    # íŠ¸ë¦¼ íŠ¹ì„± ì¶”ì¶œ
    trim_features = df.apply(lambda x: extract_trim_features(x['model_name'], x['fuel']), axis=1)
    for key in ['is_hybrid', 'is_electric', 'is_premium_trim', 'is_sport', 'is_large']:
        df[key] = trim_features.apply(lambda x: x[key])
    
    # ë¸Œëœë“œ-ì—°ë£Œ ì¡°í•©
    df['brand_fuel'] = df['brand'] + '_' + df['fuel']
    
    # ëª¨ë¸ ì¸ê¸°ë„
    model_counts = df['model_name'].value_counts()
    df['model_popularity'] = df['model_name'].map(model_counts)
    df['model_popularity_log'] = np.log1p(df['model_popularity'])
    
    # ë¸Œëœë“œë³„ í‰ê·  ê°€ê²©
    brand_price_mean = df.groupby('brand')['price'].transform('mean')
    df['brand_avg_price'] = brand_price_mean
    
    # ëª¨ë¸ë³„ í‰ê·  ê°€ê²©
    model_price_mean = df.groupby('model_name')['price'].transform('mean')
    df['model_avg_price'] = model_price_mean
    
    # ê°€ê²© vs ëª¨ë¸ í‰ê· 
    df['price_vs_model_avg'] = df['price'] / (model_price_mean + 1)
    
    # ì—°ì‹-ì£¼í–‰ê±°ë¦¬ ìƒí˜¸ì‘ìš©
    df['age_mileage_interaction'] = df['age'] * np.log1p(df['mileage'])
    
    # ì£¼í–‰ê±°ë¦¬ ê³¼ë‹¤ ì—¬ë¶€ (ì—°ê°„ 2ë§Œkm ê¸°ì¤€)
    df['is_overmileage'] = (df['mileage_per_year'] > 20000).astype(int)
    
    # ì¸ê¸° ëª¨ë¸ í‘œì‹œ
    popular_models = ['ê·¸ëœì €', 'ì•„ë°˜ë–¼', 'ì˜ë‚˜íƒ€', 'K5', 'ì‹¼íƒ€í˜', 'íˆ¬ì‹¼', 'ì˜ë Œí† ', 'ì¹´ë‹ˆë°œ', 'ìŠ¤í¬í‹°ì§€', 'ì½”ë‚˜']
    df['is_popular_model'] = df['model_name'].apply(
        lambda x: 1 if any(m in str(x) for m in popular_models) else 0
    )
    
    # SUV/ì„¸ë‹¨/MPV êµ¬ë¶„
    df['vehicle_type'] = 'sedan'
    suv_keywords = ['ì‹¼íƒ€í˜', 'íˆ¬ì‹¼', 'ì˜ë Œí† ', 'ìŠ¤í¬í‹°ì§€', 'ì…€í† ìŠ¤', 'ì½”ë‚˜', 'íŒ°ë¦¬ì„¸ì´ë“œ', 'ëª¨í•˜ë¹„']
    mpv_keywords = ['ì¹´ë‹ˆë°œ', 'ìŠ¤íƒ€ë ‰ìŠ¤', 'ìŠ¤íƒ€ë¦¬ì•„']
    
    for keyword in suv_keywords:
        df.loc[df['model_name'].str.contains(keyword, na=False), 'vehicle_type'] = 'suv'
    for keyword in mpv_keywords:
        df.loc[df['model_name'].str.contains(keyword, na=False), 'vehicle_type'] = 'mpv'
    
    # ë¡œê·¸ ë³€í™˜
    df['log_price'] = np.log1p(df['price'])
    
    print(f"     âœ“ ìƒì„±ëœ í”¼ì²˜ ìˆ˜: {len([c for c in df.columns if c not in ['price', 'log_price']])}")
    
    return df

def train_improved_model(data_path='../data/processed_encar_combined.csv',
                        model_path='../models/regular_domestic_improved.pkl'):
    """ê°œì„ ëœ ì¼ë°˜ êµ­ì‚°ì°¨ ëª¨ë¸ í•™ìŠµ"""
    
    print("\n" + "="*70)
    print("  ğŸš— ì¼ë°˜ êµ­ì‚°ì°¨ ëª¨ë¸ í•™ìŠµ (ê°œì„  ë²„ì „)")
    print("="*70)
    
    # ë°ì´í„° ë¡œë“œ
    print("\n  ğŸ“‚ ë°ì´í„° ë¡œë”©...")
    df = pd.read_csv(data_path)
    
    # êµ­ì‚°ì°¨ ì¤‘ ì œë„¤ì‹œìŠ¤ ì œì™¸
    df = df[(df['car_type'] == 'Domestic') & (df['brand'] != 'ì œë„¤ì‹œìŠ¤')].copy()
    print(f"     ì¼ë°˜ êµ­ì‚°ì°¨ ë°ì´í„°: {len(df):,}ê±´")
    
    # í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
    df = create_improved_features(df)
    
    # ì´ìƒì¹˜ ì œê±° (ë” ë³´ìˆ˜ì ìœ¼ë¡œ)
    initial_count = len(df)
    
    # 1. ê·¹ë‹¨ì  ê°€ê²©
    df = df[(df['price'] >= 100) & (df['price'] <= 8000)]
    
    # 2. ê·¹ë‹¨ì  ì£¼í–‰ê±°ë¦¬ (ì—°ê°„ 5ë§Œkm ì´ìƒì€ ì´ìƒ)
    df = df[df['mileage_per_year'] <= 50000]
    
    # 3. ë„ˆë¬´ ì˜¤ë˜ëœ ì°¨ëŸ‰ (15ë…„ ì´ìƒ)
    df = df[df['age'] <= 15]
    
    removed = initial_count - len(df)
    print(f"  ğŸ§¹ ì´ìƒì¹˜ ì œê±°: {removed:,}ê±´")
    print(f"  ìµœì¢… ë°ì´í„°: {len(df):,}ê±´")
    print(f"  ê°€ê²© ë²”ìœ„: {df['price'].min():.0f}ë§Œì› ~ {df['price'].max():.0f}ë§Œì›")
    
    # í”¼ì²˜ ì„ íƒ
    categorical_features = [
        'brand', 'model_name', 'fuel', 
        'age_group', 'mileage_group', 'generation',
        'brand_fuel', 'vehicle_type'
    ]
    
    numerical_features = [
        'age', 'mileage', 'mileage_per_year',
        'is_low_mileage', 'is_high_mileage', 'is_overmileage',
        'model_popularity_log', 'brand_avg_price', 'model_avg_price',
        'age_mileage_interaction',
        'is_hybrid', 'is_electric', 'is_premium_trim', 'is_sport', 'is_large',
        'is_popular_model'
    ]
    
    categorical_features = [f for f in categorical_features if f in df.columns]
    numerical_features = [f for f in numerical_features if f in df.columns]
    
    feature_cols = categorical_features + numerical_features
    X = df[feature_cols]
    y = df['log_price']
    
    # Train/Test split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    print(f"\n  ğŸ“Š Train: {len(X_train):,} | Test: {len(X_test):,}")
    
    # Preprocessing
    preprocessor = ColumnTransformer(
        transformers=[
            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),
            ('num', 'passthrough', numerical_features)
        ]
    )
    
    # ê°œì„ ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°
    xgb_params = {
        'n_estimators': 1500,        # ë” ë§ì€ íŠ¸ë¦¬
        'learning_rate': 0.03,       # ë” ì²œì²œíˆ í•™ìŠµ
        'max_depth': 8,              # ë” ê¹Šì€ íŠ¸ë¦¬
        'min_child_weight': 5,       # ê³¼ì í•© ë°©ì§€
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'gamma': 0.1,
        'reg_alpha': 0.1,
        'reg_lambda': 1.5,
        'objective': 'reg:squarederror',
        'random_state': 42,
        'n_jobs': -1
    }
    
    # Pipeline
    pipeline = Pipeline([
        ('preprocessor', preprocessor),
        ('model', XGBRegressor(**xgb_params))
    ])
    
    # í•™ìŠµ
    print(f"\n  ğŸš€ ëª¨ë¸ í•™ìŠµ ì¤‘...")
    pipeline.fit(X_train, y_train)
    
    # ì˜ˆì¸¡
    y_train_pred = pipeline.predict(X_train)
    y_test_pred = pipeline.predict(X_test)
    
    y_train_actual = np.expm1(y_train)
    y_test_actual = np.expm1(y_test)
    y_train_pred_actual = np.expm1(y_train_pred)
    y_test_pred_actual = np.expm1(y_test_pred)
    
    # í‰ê°€
    train_mae = mean_absolute_error(y_train_actual, y_train_pred_actual)
    test_mae = mean_absolute_error(y_test_actual, y_test_pred_actual)
    train_r2 = r2_score(y_train_actual, y_train_pred_actual)
    test_r2 = r2_score(y_test_actual, y_test_pred_actual)
    
    train_mape = np.mean(np.abs((y_train_actual - y_train_pred_actual) / y_train_actual)) * 100
    test_mape = np.mean(np.abs((y_test_actual - y_test_pred_actual) / y_test_actual)) * 100
    
    print(f"\n  ğŸ“ˆ ì„±ëŠ¥ ì§€í‘œ:")
    print(f"     Train MAE: {train_mae:.0f}ë§Œì› | MAPE: {train_mape:.2f}%")
    print(f"     Test MAE:  {test_mae:.0f}ë§Œì› | MAPE: {test_mape:.2f}%")
    print(f"     Train RÂ²:  {train_r2:.4f}")
    print(f"     Test RÂ²:   {test_r2:.4f}")
    
    # Cross Validation
    print(f"\n  ğŸ”„ K-Fold Cross Validation (k=5)...")
    kfold = KFold(n_splits=5, shuffle=True, random_state=42)
    cv_scores = cross_val_score(pipeline, X, y, cv=kfold, scoring='r2', n_jobs=-1)
    print(f"     CV RÂ² scores: {cv_scores}")
    print(f"     í‰ê·  CV RÂ²: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})")
    
    r2_gap = abs(train_r2 - cv_scores.mean())
    if r2_gap < 0.05:
        print(f"     âœ… ê³¼ì í•© ì—†ìŒ (Train-CV ì°¨ì´: {r2_gap:.4f})")
    else:
        print(f"     âš ï¸  ê³¼ì í•© ê°€ëŠ¥ì„± (Train-CV ì°¨ì´: {r2_gap:.4f})")
    
    # ëª¨ë¸ ì €ì¥
    os.makedirs(os.path.dirname(model_path), exist_ok=True)
    joblib.dump(pipeline, model_path)
    print(f"\n  âœ… ëª¨ë¸ ì €ì¥: {model_path}")
    
    # ê°€ê²©ëŒ€ë³„ ì„±ëŠ¥
    print(f"\n  ğŸ’° ê°€ê²©ëŒ€ë³„ ì˜ˆì¸¡ ì •í™•ë„:")
    
    price_ranges = [
        (0, 1000, "ì €ê°€ (<1000ë§Œì›)"),
        (1000, 2000, "ì¤‘ì €ê°€ (1000-2000ë§Œì›)"),
        (2000, 3000, "ì¤‘ê°€ (2000-3000ë§Œì›)"),
        (3000, 5000, "ê³ ê°€ (3000-5000ë§Œì›)"),
        (5000, 10000, "ì´ˆê³ ê°€ (5000ë§Œì›+)")
    ]
    
    for min_p, max_p, label in price_ranges:
        mask = (y_test_actual >= min_p) & (y_test_actual < max_p)
        if mask.sum() == 0:
            continue
        
        subset_mae = mean_absolute_error(y_test_actual[mask], y_test_pred_actual[mask])
        subset_mape = np.mean(np.abs((y_test_actual[mask] - y_test_pred_actual[mask]) / y_test_actual[mask])) * 100
        print(f"     {label:25s}: MAE {subset_mae:5.0f}ë§Œì›, MAPE {subset_mape:5.1f}%, N={mask.sum():,}")
    
    return {
        'data_count': len(df),
        'train_mae': train_mae,
        'test_mae': test_mae,
        'train_r2': train_r2,
        'test_r2': test_r2,
        'cv_r2': cv_scores.mean(),
        'test_mape': test_mape
    }

if __name__ == "__main__":
    result = train_improved_model()
    
    print("\n" + "="*70)
    print("  ğŸ‰ ê°œì„ ëœ ì¼ë°˜ êµ­ì‚°ì°¨ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    print("="*70)
    
    print(f"\nğŸ“Š ìµœì¢… ì„±ëŠ¥:")
    print(f"   Test RÂ²: {result['test_r2']:.4f}")
    print(f"   Test MAE: {result['test_mae']:.0f}ë§Œì›")
    print(f"   Test MAPE: {result['test_mape']:.2f}%")
    print(f"   CV RÂ²: {result['cv_r2']:.4f}")
