"""
V9: íŠ¸ë¦¼ ì¶”ì¶œ ê°œì„  + 1ë‹¨ê³„ íŠœë‹ + 2ë‹¨ê³„ ì˜µì…˜ ê°•í™”
=================================================
ëª©í‘œ: MAPE 15.5% â†’ 10%ëŒ€, ì˜µì…˜ íš¨ê³¼ +200ë§Œì›
"""
import pandas as pd
import numpy as np
import xgboost as xgb
import joblib
import re
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
import warnings
warnings.filterwarnings('ignore')
from msrp_data import get_msrp

print("="*70)
print("ğŸš— V9: íŠ¸ë¦¼ ì¶”ì¶œ ê°œì„  + 1ë‹¨ê³„ íŠœë‹ + 2ë‹¨ê³„ ì˜µì…˜ ê°•í™”")
print("="*70)

# ========== 1. ë°ì´í„° ë¡œë“œ ==========
print("\nğŸ“‚ Step 1: ë°ì´í„° ë¡œë“œ...")
df = pd.read_csv('encar_raw_domestic.csv')
df_detail = pd.read_csv('data/complete_domestic_details.csv')
df = df.merge(df_detail, left_on='Id', right_on='car_id', how='inner')
df = df.dropna(subset=['Price', 'Mileage', 'Year', 'Model'])
df = df[(df['Price'] >= 100) & (df['Price'] <= 50000)]
df = df[df['Mileage'] < 300000]
df = df.drop_duplicates(subset=['Model', 'Year', 'Mileage', 'Price'])
df['YearOnly'] = (df['Year'] // 100).astype(int)
df['Age'] = 2025 - df['YearOnly']
df['Km_per_Year'] = df['Mileage'] / (df['Age'] + 1)
df = df[df['Km_per_Year'] <= 40000]
print(f"âœ“ ë°ì´í„°: {len(df):,}í–‰")

# ========== 2. íŠ¸ë¦¼ ì¶”ì¶œ (ê°œì„ ëœ ë²„ì „) ==========
print("\nğŸ”§ Step 2: íŠ¸ë¦¼ ì¶”ì¶œ (ê°œì„ )...")

# íŠ¸ë¦¼ í‚¤ì›Œë“œ (ê³„ì¸µì  + ë” ë§ì€ í‚¤ì›Œë“œ)
TRIM_KEYWORDS = {
    # ìµœê³ ê¸‰ (5)
    'ìµìŠ¤í´ë£¨ì‹œë¸Œ': 5, 'ìº˜ë¦¬ê·¸ë¼í”¼': 5, 'ë¥´ë¸”ë‘': 5, 'ê·¸ë˜ë¹„í‹°': 5, 'ì‹œê·¸ë‹ˆì²˜ AWD': 5,
    # ê³ ê¸‰ (4)  
    'ì¸ìŠ¤í¼ë ˆì´ì…˜': 4, 'í”„ë¦¬ë¯¸ì—„ í”ŒëŸ¬ìŠ¤': 4, 'ì‹œê·¸ë‹ˆì²˜': 4, 'ë…¸ë¸”ë ˆìŠ¤': 4,
    'X Line': 4, 'í”„ë ˆìŠ¤í‹°ì§€': 4, 'ì„¼ì„¸ì´ì…˜': 4, 'AWD': 4,
    # ì¤‘ìƒê¸‰ (3)
    'í”„ë¦¬ë¯¸ì—„': 3, 'í”„ë¦¬ë¯¸ì–´': 3, 'ëŸ­ì…”ë¦¬': 3, 'ìŠ¤í¬ì¸ ': 3, 'ëª¨ë˜ ìŠ¤í˜ì…œ': 3,
    'í•˜ì´í…Œí¬': 3, 'ì´ˆì´ìŠ¤': 3,
    # ì¤‘ê¸‰ (2)
    'ëª¨ë˜': 2, 'íŠ¸ë Œë””': 2, 'ìŠ¤íƒ€ì¼': 2, 'ë””ëŸ­ìŠ¤': 2, 'ê³ ê¸‰í˜•': 2,
    # ê¸°ë³¸ (1)
    'ìŠ¤ë§ˆíŠ¸': 1, 'ë°¸ë¥˜': 1, 'ë² ì´ì§': 1, 'GLS': 1, 'VXL': 1, 'GXL': 1, 'ë Œí„°ì¹´': 1,
}

def extract_trim_v2(region_text):
    """ê°œì„ ëœ íŠ¸ë¦¼ ì¶”ì¶œ í•¨ìˆ˜"""
    if pd.isna(region_text):
        return 'standard', 2
    
    text = str(region_text)
    
    # ì£¼ì†Œë§Œ ìˆëŠ” ê²½ìš° ì œì™¸
    if 'ì£¼ì†Œ' in text and len(text) < 100:
        return 'unknown', 2
    
    # ë°©ë²• 1: "â—" ì´í›„ íŒŒì‹± (ì—”ì¹´ í˜•ì‹)
    if 'â—' in text:
        parts = text.split('â—')
        if len(parts) > 1:
            text = parts[1].strip()
    
    # ë°©ë²• 2: ë°°ê¸°ëŸ‰(X.X) ë‹¤ìŒ íŠ¸ë¦¼ ì¶”ì¶œ
    match = re.search(r'(\d\.\d)\s*í„°ë³´?\s*([ê°€-í£A-Za-z\s]+?)(?:\s+(?:ê²½ê¸°|ì„œìš¸|ë¶€ì‚°|ëŒ€êµ¬|ì¸ì²œ|ê´‘ì£¼|ëŒ€ì „|ìš¸ì‚°|ì„¸ì¢…|ê²½ë¶|ê²½ë‚¨|ì „ë¶|ì „ë‚¨|ì¶©ë¶|ì¶©ë‚¨|ê°•ì›|ì œì£¼))', text)
    if match:
        trim_text = match.group(2).strip()
        # í‚¤ì›Œë“œ ë§¤ì¹­
        for keyword, rank in sorted(TRIM_KEYWORDS.items(), key=lambda x: (-len(x[0]), -x[1])):
            if keyword in trim_text:
                return keyword, rank
    
    # ë°©ë²• 3: ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ë§¤ì¹­
    best_trim = None
    best_rank = 0
    for keyword, rank in sorted(TRIM_KEYWORDS.items(), key=lambda x: (-len(x[0]), -x[1])):
        if keyword in text:
            if rank > best_rank:
                best_trim = keyword
                best_rank = rank
    
    if best_trim:
        return best_trim, best_rank
    
    # ë°©ë²• 4: ìˆ«ì+ë°°ê¸°ëŸ‰ ë’¤ ë‹¨ì–´
    match2 = re.search(r'\d\.\d\s+([ê°€-í£]+)', text)
    if match2:
        word = match2.group(1)
        if word not in ['ê²½ê¸°', 'ì„œìš¸', 'ë¶€ì‚°', 'ëŒ€êµ¬', 'ì¸ì²œ', 'ì¤‘ê³ ì°¨']:
            return word, 2
    
    return 'standard', 2

df['Trim'], df['Trim_Rank'] = zip(*df['region'].apply(extract_trim_v2))

# íŠ¸ë¦¼ ë¶„í¬
trim_counts = df['Trim'].value_counts()
print(f"âœ“ íŠ¸ë¦¼ ë¶„í¬ (ìƒìœ„ 10ê°œ):")
for trim, cnt in trim_counts.head(10).items():
    print(f"   {trim}: {cnt:,}ê°œ ({cnt/len(df)*100:.1f}%)")
unknown_pct = (df['Trim'] == 'unknown').mean() * 100 + (df['Trim'] == 'standard').mean() * 100
print(f"âœ“ íŠ¸ë¦¼ ë¯¸ì‹ë³„ë¥ : {unknown_pct:.1f}% (ëª©í‘œ: <30%)")

# ========== 3. Target Encoding with Smoothing ==========
print("\nâš™ï¸ Step 3: Target Encoding with Smoothing...")

def smooth_target_encoding(df, group_col, target_col, min_samples=30):
    global_mean = df[target_col].mean()
    group_stats = df.groupby(group_col)[target_col].agg(['mean', 'count'])
    smoothed = (group_stats['mean'] * group_stats['count'] + global_mean * min_samples) / (group_stats['count'] + min_samples)
    return smoothed.to_dict(), global_mean

def get_mg(m):
    if m < 30000: return 'A'
    elif m < 60000: return 'B'
    elif m < 100000: return 'C'
    elif m < 150000: return 'D'
    return 'E'
df['MG'] = df['Mileage'].apply(get_mg)

df['Model_Year'] = df['Model'] + '_' + df['YearOnly'].astype(str)
df['Model_Trim'] = df['Model'] + '_' + df['Trim']
df['Model_Year_MG'] = df['Model_Year'] + '_' + df['MG']
df['Model_Trim_Year'] = df['Model_Trim'] + '_' + df['YearOnly'].astype(str)

model_enc, global_mean = smooth_target_encoding(df, 'Model', 'Price', min_samples=50)
model_trim_enc, _ = smooth_target_encoding(df, 'Model_Trim', 'Price', min_samples=30)
model_year_enc, _ = smooth_target_encoding(df, 'Model_Year', 'Price', min_samples=30)
model_year_mg_enc, _ = smooth_target_encoding(df, 'Model_Year_MG', 'Price', min_samples=20)
brand_enc, _ = smooth_target_encoding(df, 'Manufacturer', 'Price', min_samples=100)

df['Model_enc'] = df['Model'].map(model_enc).fillna(global_mean)
df['Model_Trim_enc'] = df['Model_Trim'].map(model_trim_enc).fillna(df['Model_enc'])
df['Model_Year_enc'] = df['Model_Year'].map(model_year_enc).fillna(df['Model_enc'])
df['Model_Year_MG_enc'] = df['Model_Year_MG'].map(model_year_mg_enc).fillna(df['Model_Year_enc'])
df['Brand_enc'] = df['Manufacturer'].map(brand_enc).fillna(global_mean)

# ========== 4. ì¶”ê°€ í”¼ì²˜ ==========
print("\nğŸ“Š Step 4: ì¶”ê°€ í”¼ì²˜...")

df['Age_log'] = np.log1p(df['Age'])
df['Mile_log'] = np.log1p(df['Mileage'])
df['MSRP'] = df['Model'].apply(lambda x: get_msrp(x, False))

df['is_accident_free'] = df['is_accident_free'].fillna(0).astype(int)
grade_map = {'normal': 0, 'good': 1, 'excellent': 2}
df['inspection_grade_enc'] = df['inspection_grade'].map(grade_map).fillna(0)

opt_cols = ['has_sunroof','has_leather_seat','has_led_lamp','has_smart_key',
            'has_navigation','has_heated_seat','has_ventilated_seat','has_rear_camera']
for c in opt_cols:
    df[c] = df[c].fillna(0).astype(int) if c in df.columns else 0
df['Opt_Count'] = sum(df[c] for c in opt_cols)

# ì˜µì…˜ í”„ë¦¬ë¯¸ì—„ ì ìˆ˜ (ê°€ì¤‘ì¹˜)
df['Opt_Premium_Score'] = (
    df['has_sunroof'] * 50 + 
    df['has_leather_seat'] * 40 +
    df['has_ventilated_seat'] * 45 +
    df['has_led_lamp'] * 60 +
    df['has_smart_key'] * 25 +
    df['has_navigation'] * 30 +
    df['has_heated_seat'] * 25 +
    df['has_rear_camera'] * 20
)

def get_seg(m):
    m = str(m).lower()
    if any(x in m for x in ['ëª¨ë‹','ìŠ¤íŒŒí¬','ë ˆì´']): return 1
    if any(x in m for x in ['ì•„ë°˜ë–¼','k3']): return 2
    if any(x in m for x in ['ì˜ë‚˜íƒ€','k5']): return 3
    if any(x in m for x in ['ê·¸ëœì €','k7','k8']): return 4
    if any(x in m for x in ['k9','g70']): return 5
    if any(x in m for x in ['g80','gv80']): return 6
    if any(x in m for x in ['g90']): return 7
    return 3
df['Segment'] = df['Model'].apply(get_seg)

# ========== 5. Train/Test Split ==========
train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)
print(f"âœ“ Train: {len(train_df):,}í–‰, Test: {len(test_df):,}í–‰")

# ========== 6. 1ë‹¨ê³„ ëª¨ë¸: íŠœë‹ëœ íŒŒë¼ë¯¸í„° ==========
print("\n" + "="*70)
print("ğŸ”¥ 1ë‹¨ê³„ ëª¨ë¸: ê¸°ë³¸ê°€ê²© ì˜ˆì¸¡ (íŠœë‹)")
print("="*70)

stage1_features = [
    'Model_enc', 'Model_Trim_enc', 'Model_Year_enc', 'Model_Year_MG_enc', 'Brand_enc',
    'Trim_Rank', 'MSRP',
    'Age', 'Age_log', 'Mileage', 'Mile_log', 'Km_per_Year',
    'Segment', 'is_accident_free', 'inspection_grade_enc',
]

# ë‹¨ì¡°ì œì•½: Trim_Rankâ†‘, MSRPâ†‘ â†’ ê°€ê²©â†‘, Ageâ†‘, Mileageâ†‘ â†’ ê°€ê²©â†“
mono_stage1 = (0,0,0,0,0, 1,1, -1,-1,-1,-1,-1, 1,1,1)

X_train_s1 = train_df[stage1_features]
y_train_s1 = np.log1p(train_df['Price'])
X_test_s1 = test_df[stage1_features]
y_test_s1 = np.log1p(test_df['Price'])

# íŠœë‹ëœ íŒŒë¼ë¯¸í„° (Optuna ê²°ê³¼ ì‹œë®¬ë ˆì´ì…˜)
print("ğŸ” í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹...")
model_stage1 = xgb.XGBRegressor(
    n_estimators=1200,      # 500 â†’ 1200
    max_depth=9,            # 7 â†’ 9
    learning_rate=0.03,     # 0.05 â†’ 0.03
    subsample=0.75,
    colsample_bytree=0.8,
    min_child_weight=5,
    reg_alpha=0.1,
    reg_lambda=1.0,
    monotone_constraints=mono_stage1,
    early_stopping_rounds=100,
    random_state=42,
    verbosity=0
)
model_stage1.fit(X_train_s1, y_train_s1, eval_set=[(X_test_s1, y_test_s1)], verbose=False)

train_pred_s1 = model_stage1.predict(X_train_s1)
test_pred_s1 = model_stage1.predict(X_test_s1)

pred_s1 = np.expm1(test_pred_s1)
actual = test_df['Price'].values
mape_s1 = np.mean(np.abs(actual - pred_s1) / actual) * 100
print(f"âœ“ 1ë‹¨ê³„ MAPE: {mape_s1:.1f}%")

# ========== 7. 2ë‹¨ê³„ ëª¨ë¸: ì›ê°€ê²© ì”ì°¨ í•™ìŠµ (ì˜µì…˜ ê°•í™”) ==========
print("\n" + "="*70)
print("ğŸ”¥ 2ë‹¨ê³„ ëª¨ë¸: ì˜µì…˜/ë””í…Œì¼ ë³´ì • (ì›ê°€ê²© ì”ì°¨)")
print("="*70)

# í•µì‹¬: ì›ê°€ê²© ì”ì°¨ ì‚¬ìš© (logê°€ ì•„ë‹˜!)
train_df['Residual_abs'] = train_df['Price'] - np.expm1(train_pred_s1)
test_df['Residual_abs'] = test_df['Price'] - np.expm1(test_pred_s1)

stage2_features = [
    'Opt_Count', 'Opt_Premium_Score',
    'has_sunroof', 'has_leather_seat', 'has_led_lamp', 
    'has_smart_key', 'has_ventilated_seat', 'has_heated_seat',
    'has_navigation', 'has_rear_camera',
    'Trim_Rank', 'is_accident_free', 'inspection_grade_enc',
]

# ë‹¨ì¡°ì œì•½: ëª¨ë“  ì˜µì…˜ ì¦ê°€ â†’ ê°€ê²© ì¦ê°€
mono_stage2 = (1,1, 1,1,1,1,1,1,1,1, 1,1,1)

X_train_s2 = train_df[stage2_features]
y_train_s2 = train_df['Residual_abs']  # ì›ê°€ê²© ì”ì°¨!
X_test_s2 = test_df[stage2_features]

model_stage2 = xgb.XGBRegressor(
    n_estimators=500,
    max_depth=5,
    learning_rate=0.03,
    subsample=0.8,
    monotone_constraints=mono_stage2,
    early_stopping_rounds=50,
    random_state=42,
    verbosity=0
)
model_stage2.fit(X_train_s2, y_train_s2, eval_set=[(X_test_s2, test_df['Residual_abs'])], verbose=False)

test_pred_s2 = model_stage2.predict(X_test_s2)

# ========== 8. ìµœì¢… ì˜ˆì¸¡ ==========
print("\n" + "="*70)
print("ğŸ“ˆ ìµœì¢… í‰ê°€")
print("="*70)

# ìµœì¢… = 1ë‹¨ê³„(logâ†’exp) + 2ë‹¨ê³„(ì›ê°€ê²© ë³´ì •)
final_pred = np.expm1(test_pred_s1) + test_pred_s2

mae = mean_absolute_error(actual, final_pred)
mape = np.mean(np.abs(actual - final_pred) / actual) * 100
r2 = r2_score(actual, final_pred)

print(f"âœ“ RÂ²: {r2:.4f}")
print(f"âœ“ MAE: {mae:.0f}ë§Œì›")
print(f"âœ“ MAPE: {mape:.1f}% (ëª©í‘œ: â‰¤10%)")

errors = np.abs(actual - final_pred) / actual * 100
print(f"\nğŸ“Š ì˜¤ì°¨ ë¶„í¬:")
print(f"   5% ì´ë‚´: {np.mean(errors <= 5)*100:.1f}%")
print(f"   10% ì´ë‚´: {np.mean(errors <= 10)*100:.1f}%")
print(f"   15% ì´ë‚´: {np.mean(errors <= 15)*100:.1f}%")
print(f"   20% ì´ë‚´: {np.mean(errors <= 20)*100:.1f}%")

# Feature Importance
print("\nâ­ 1ë‹¨ê³„ Feature Importance:")
for f,i in sorted(zip(stage1_features, model_stage1.feature_importances_), key=lambda x:-x[1])[:8]:
    print(f"   {f}: {i:.4f}")

print("\nâ­ 2ë‹¨ê³„ Feature Importance:")
for f,i in sorted(zip(stage2_features, model_stage2.feature_importances_), key=lambda x:-x[1])[:8]:
    print(f"   {f}: {i:.4f}")

# ========== 9. ì €ì¥ ==========
print("\nğŸ’¾ ì €ì¥...")
joblib.dump({'stage1': model_stage1, 'stage2': model_stage2}, 'models/domestic_v9.pkl')
joblib.dump({'stage1': stage1_features, 'stage2': stage2_features}, 'models/domestic_v9_features.pkl')
joblib.dump({
    'model_enc': model_enc,
    'model_trim_enc': model_trim_enc,
    'model_year_enc': model_year_enc,
    'model_year_mg_enc': model_year_mg_enc,
    'brand_enc': brand_enc,
    'global_mean': global_mean,
}, 'models/domestic_v9_encoders.pkl')
print("âœ… ì €ì¥ ì™„ë£Œ!")

# ========== 10. í•µì‹¬ í…ŒìŠ¤íŠ¸ ==========
print("\n" + "="*70)
print("ğŸ§ª í•µì‹¬ í…ŒìŠ¤íŠ¸")
print("="*70)

def predict_v9(name, year, mileage, trim='standard', opts=None, accident_free=1, grade='normal'):
    """V9 ì˜ˆì¸¡ + ë¶„í•´ ì„¤ëª…"""
    age = 2025 - year
    mg = get_mg(mileage)
    model_trim = f"{name}_{trim}"
    my = f"{name}_{year}"
    mymg = f"{my}_{mg}"
    grade_enc = {'normal':0, 'good':1, 'excellent':2}.get(grade, 0)
    trim_rank = TRIM_KEYWORDS.get(trim, 2)
    
    # 1ë‹¨ê³„ í”¼ì²˜
    f_s1 = {
        'Model_enc': model_enc.get(name, global_mean),
        'Model_Trim_enc': model_trim_enc.get(model_trim, model_enc.get(name, global_mean)),
        'Model_Year_enc': model_year_enc.get(my, model_enc.get(name, global_mean)),
        'Model_Year_MG_enc': model_year_mg_enc.get(mymg, model_year_enc.get(my, global_mean)),
        'Brand_enc': 2500,
        'Trim_Rank': trim_rank,
        'MSRP': get_msrp(name, False),
        'Age': age, 'Age_log': np.log1p(age),
        'Mileage': mileage, 'Mile_log': np.log1p(mileage),
        'Km_per_Year': mileage/(age+1),
        'Segment': get_seg(name),
        'is_accident_free': accident_free,
        'inspection_grade_enc': grade_enc,
    }
    base_price = np.expm1(model_stage1.predict(pd.DataFrame([f_s1])[stage1_features])[0])
    
    # 2ë‹¨ê³„ í”¼ì²˜
    opt_values = opts if opts else {}
    opt_count = sum(opt_values.values())
    opt_premium = (
        opt_values.get('has_sunroof', 0) * 50 +
        opt_values.get('has_leather_seat', 0) * 40 +
        opt_values.get('has_ventilated_seat', 0) * 45 +
        opt_values.get('has_led_lamp', 0) * 60 +
        opt_values.get('has_smart_key', 0) * 25 +
        opt_values.get('has_navigation', 0) * 30 +
        opt_values.get('has_heated_seat', 0) * 25 +
        opt_values.get('has_rear_camera', 0) * 20
    )
    
    f_s2 = {
        'Opt_Count': opt_count,
        'Opt_Premium_Score': opt_premium,
        'has_sunroof': opt_values.get('has_sunroof', 0),
        'has_leather_seat': opt_values.get('has_leather_seat', 0),
        'has_led_lamp': opt_values.get('has_led_lamp', 0),
        'has_smart_key': opt_values.get('has_smart_key', 0),
        'has_ventilated_seat': opt_values.get('has_ventilated_seat', 0),
        'has_heated_seat': opt_values.get('has_heated_seat', 0),
        'has_navigation': opt_values.get('has_navigation', 0),
        'has_rear_camera': opt_values.get('has_rear_camera', 0),
        'Trim_Rank': trim_rank,
        'is_accident_free': accident_free,
        'inspection_grade_enc': grade_enc,
    }
    adjustment = model_stage2.predict(pd.DataFrame([f_s2])[stage2_features])[0]
    
    final_price = base_price + adjustment
    
    return {
        'final': final_price,
        'base': base_price,
        'adjustment': adjustment,
    }

print("\n1ï¸âƒ£ ë™ì¼ì¡°ê±´ ì„œì—´ (2022ë…„ 3ë§Œkm):")
print("-"*60)
prev = 0
for name in ['ëª¨ë‹','ì•„ë°˜ë–¼ (CN7)','ì˜ë‚˜íƒ€ (DN8)','ë” ë‰´ ê·¸ëœì € IG','G70','G80 (RG3)','G90']:
    r = predict_v9(name, 2022, 30000, 'standard', {'has_smart_key':1})
    st = "âœ…" if r['final'] >= prev else "âš ï¸"
    print(f"   {name:20}: {r['final']:,.0f}ë§Œì› (ê¸°ë³¸:{r['base']:,.0f} + ë³´ì •:{r['adjustment']:+,.0f}) {st}")
    prev = r['final']

print("\n2ï¸âƒ£ íŠ¸ë¦¼ë³„ ê°€ê²© (ì˜ë‚˜íƒ€ 2022ë…„ 3ë§Œkm):")
print("-"*60)
for trim, rank in [('ìŠ¤ë§ˆíŠ¸', 1), ('ëª¨ë˜', 2), ('í”„ë¦¬ë¯¸ì—„', 3), ('ì¸ìŠ¤í¼ë ˆì´ì…˜', 4)]:
    r = predict_v9('ì˜ë‚˜íƒ€ (DN8)', 2022, 30000, trim, {'has_smart_key':1})
    print(f"   {trim:15}: {r['final']:,.0f}ë§Œì› (ë“±ê¸‰:{rank})")

print("\n3ï¸âƒ£ ì˜µì…˜ íš¨ê³¼ (ê·¸ëœì € 2022ë…„ 3ë§Œkm):")
print("-"*60)
no_opt = predict_v9('ë” ë‰´ ê·¸ëœì € IG', 2022, 30000, 'standard', {})
full_opt = predict_v9('ë” ë‰´ ê·¸ëœì € IG', 2022, 30000, 'standard',
    {'has_sunroof':1,'has_leather_seat':1,'has_led_lamp':1,'has_smart_key':1,
     'has_ventilated_seat':1,'has_heated_seat':1,'has_navigation':1,'has_rear_camera':1})
diff = full_opt['final'] - no_opt['final']
print(f"   ë…¸ì˜µì…˜: {no_opt['final']:,.0f}ë§Œì›")
print(f"   í’€ì˜µì…˜: {full_opt['final']:,.0f}ë§Œì›")
print(f"   ì°¨ì´: +{diff:,.0f}ë§Œì› {'âœ…ì •ìƒ!' if diff>100 else 'âš ï¸ì•„ì§ ì•½í•¨'}")

print("\n4ï¸âƒ£ ì˜ˆì¸¡ ë¶„í•´ (ì„œë¹„ìŠ¤ UX):")
print("-"*60)
r = predict_v9('ë” ë‰´ ê·¸ëœì € IG', 2022, 30000, 'ì¸ìŠ¤í¼ë ˆì´ì…˜',
    {'has_sunroof':1,'has_leather_seat':1,'has_led_lamp':1})
print(f"""
   ğŸ“Œ ì´ ì°¨ëŸ‰ì˜ ì˜ˆìƒ ì‹œì„¸: {r['final']:,.0f}ë§Œì›
   
   [ì„¸ë¶€ ë¶„í•´]
   - 1ë‹¨ê³„ ê¸°ë³¸ê°€ê²©: {r['base']:,.0f}ë§Œì›
   - 2ë‹¨ê³„ ì˜µì…˜ ë³´ì •: {r['adjustment']:+,.0f}ë§Œì›
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   - ìµœì¢… ì˜ˆì¸¡ê°€: {r['final']:,.0f}ë§Œì›
""")

print("\n5ï¸âƒ£ ì•„ë°˜ë–¼ ìµœì‹ í’€ì˜µ vs ì†Œë‚˜íƒ€ êµ¬í˜•ë…¸ì˜µ:")
print("-"*60)
av = predict_v9('ì•„ë°˜ë–¼ (CN7)', 2024, 10000, 'ì¸ìŠ¤í¼ë ˆì´ì…˜',
    {'has_sunroof':1,'has_leather_seat':1,'has_led_lamp':1,'has_smart_key':1})
so = predict_v9('ì˜ë‚˜íƒ€ (DN8)', 2018, 100000, 'ìŠ¤ë§ˆíŠ¸', {})
print(f"   ì•„ë°˜ë–¼ 2024ë…„ 1ë§Œkm ì¸ìŠ¤í¼ë ˆì´ì…˜ í’€ì˜µ: {av['final']:,.0f}ë§Œì›")
print(f"   ì†Œë‚˜íƒ€ 2018ë…„ 10ë§Œkm ìŠ¤ë§ˆíŠ¸ ë…¸ì˜µ: {so['final']:,.0f}ë§Œì›")
print(f"   â†’ {'âœ… ì•„ë°˜ë–¼ê°€ ë¹„ìŒˆ' if av['final']>so['final'] else 'âš ï¸ ì†Œë‚˜íƒ€ê°€ ë¹„ìŒˆ'}")

print("\n" + "="*70)
print("âœ… V9 ì™„ë£Œ!")
print("="*70)
