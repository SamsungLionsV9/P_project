import requests
import json
import pandas as pd
import time
import random
import os

def scrape_encar_imported(output_file="encar_imported_data.csv", batch_size=100):
    """
    ì—”ì¹´ì—ì„œ ìˆ˜ì…ì°¨ ë°ì´í„° ìˆ˜ì§‘
    CarType.N = ìˆ˜ì…ì°¨ (Imported Cars)
    """
    url = "http://api.encar.com/search/car/list/general"
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
        "Referer": "http://www.encar.com/"
    }
    
    # Initialize file
    if os.path.exists(output_file):
        print(f"âš ï¸  ê¸°ì¡´ íŒŒì¼ ì‚­ì œ: {output_file}")
        os.remove(output_file)
        
    columns = ["Id", "Manufacturer", "Model", "Badge", "Year", "FormYear", "Mileage", "FuelType", "Price", "OfficeCityState", "CarType"]
    dummy_df = pd.DataFrame(columns=columns)
    dummy_df.to_csv(output_file, index=False, encoding="utf-8-sig")
    
    print("ğŸš— ìˆ˜ì…ì°¨ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
    print("=" * 60)
    
    # Define price ranges (50ë§Œì› ë‹¨ìœ„)
    ranges = []
    step = 50  # 50ë§Œì› ë‹¨ìœ„
    for i in range(0, 15000, step):
        ranges.append((i, i + step))
    ranges.append((15000, 999999))  # ê³ ê°€ ì°¨ëŸ‰
    
    total_collected = 0
    collected_ids = set()
    
    for idx, (min_p, max_p) in enumerate(ranges, 1):
        print(f"\n[{idx}/{len(ranges)}] ê°€ê²©ëŒ€: {min_p:,}ë§Œì› ~ {max_p:,}ë§Œì›")
        
        # Query: CarType.N = ìˆ˜ì…ì°¨
        q = f"(And.Hidden.N._.CarType.N._.Price.range({min_p}..{max_p}).)"
        init_params = {
            "count": "true",
            "q": q,
            "sr": "|ModifiedDate|0|1",
            "inav": "|Metadata|Sort,0|List,0,1",
            "curid": "0",
            "usid": "0"
        }
        
        try:
            resp = requests.get(url, params=init_params, headers=headers, timeout=10)
            count = resp.json().get('Count', 0)
            print(f"  ğŸ“Š ë°œê²¬: {count}ëŒ€")
            
            if count == 0:
                continue
                
        except Exception as e:
            print(f"  âŒ ì¹´ìš´íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            time.sleep(2)
            continue
            
        # Collect items
        start = 0
        range_collected = 0
        
        while start < count:
            # Safety limit
            if start >= 8000:
                print("  âš ï¸  ì˜¤í”„ì…‹ í•œê³„ ë„ë‹¬ (8000)")
                break
                
            params = {
                "count": "true",
                "q": q,
                "sr": f"|ModifiedDate|{start}|{batch_size}",
                "inav": f"|Metadata|Sort,0|List,{start},{batch_size}",
                "curid": "0",
                "usid": "0"
            }
            
            try:
                response = requests.get(url, params=params, headers=headers, timeout=10)
                if response.status_code != 200:
                    print(f"  âš ï¸  HTTP {response.status_code}")
                    time.sleep(2)
                    continue
                    
                data = response.json()
                items = data.get('SearchResults', [])
                
                if not items:
                    break
                
                extracted_data = []
                for item in items:
                    car_id = item.get("Id")
                    if car_id in collected_ids:
                        continue
                        
                    collected_ids.add(car_id)
                    extracted_data.append({
                        "Id": car_id,
                        "Manufacturer": item.get("Manufacturer"),
                        "Model": item.get("Model"),
                        "Badge": item.get("Badge"),
                        "Year": item.get("Year"),
                        "FormYear": item.get("FormYear"),
                        "Mileage": item.get("Mileage"),
                        "FuelType": item.get("FuelType"),
                        "Price": item.get("Price"),
                        "OfficeCityState": item.get("OfficeCityState"),
                        "CarType": "Imported"  # ìˆ˜ì…ì°¨ í‘œì‹œ
                    })
                
                if extracted_data:
                    df = pd.DataFrame(extracted_data)
                    df.to_csv(output_file, mode='a', header=False, index=False, encoding="utf-8-sig")
                    range_collected += len(extracted_data)
                    total_collected += len(extracted_data)
                    print(f"  âœ“ ìˆ˜ì§‘: {range_collected}ëŒ€ (ëˆ„ì : {total_collected:,}ëŒ€)", end='\r')
                
                start += batch_size
                time.sleep(0.1)
                
            except Exception as e:
                print(f"\n  âŒ ì˜¤ë¥˜: {e}")
                time.sleep(2)
                continue
        
        if range_collected > 0:
            print(f"  âœ“ ì™„ë£Œ: {range_collected}ëŒ€ ìˆ˜ì§‘ (ëˆ„ì  ì´í•©: {total_collected:,}ëŒ€)")
    
    print("\n" + "=" * 60)
    print(f"âœ… ìˆ˜ì…ì°¨ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {os.path.abspath(output_file)}")
    print(f"ğŸ“Š ì´ ìˆ˜ì§‘ëŸ‰: {total_collected:,}ëŒ€")
    
    return total_collected

if __name__ == "__main__":
    total = scrape_encar_imported()
    print(f"\nğŸ‰ ìµœì¢… ê²°ê³¼: {total:,}ëŒ€ì˜ ìˆ˜ì…ì°¨ ë°ì´í„° ìˆ˜ì§‘")
