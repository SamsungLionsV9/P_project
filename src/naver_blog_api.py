"""
ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ APIë¥¼ ì‚¬ìš©í•œ ì»¤ë®¤ë‹ˆí‹° ê°ì„± ë¶„ì„
- í¬ë¡¤ë§ ì—†ì´ ê³µì‹ API ì‚¬ìš©
- ì•ˆì •ì ì¸ ë°ì´í„° ìˆ˜ì§‘
"""

import os
import requests
from datetime import datetime, timedelta
import time


POSITIVE_KEYWORDS = [
    "ë¹ ë¥´ë‹¤", "ì¡°ìš©", "ë¶€ë“œëŸ½", "ì•ˆì •ì ", "íƒ„íƒ„", "ê²¬ê³ ",
    "ê°€ì„±ë¹„", "ì €ë ´", "í•©ë¦¬ì ", "í˜œì",
    "ì¶”ì²œ", "ë§Œì¡±", "ì¢‹ìŒ", "í›Œë¥­", "ìµœê³ ", "êµ¿", "ê´œì°®",
    "ê³„ì•½", "êµ¬ì…", "ìƒ€ì–´", "ì§ˆë €",
    "ì˜ˆì˜", "ë©‹ì§€", "ê³ ê¸‰", "ì„¸ë ¨",
    "í¸í•˜", "ì¾Œì ", "ë„“", "ì‹¤ìš©",
]

NEGATIVE_KEYWORDS = [
    "ê³ ì¥", "ê²°í•¨", "í•˜ì", "ë¬¸ì œ", "ì´ìŠˆ", "ë¶ˆëŸ‰",
    "ì‹¤ë§", "í›„íšŒ", "ìµœì•…", "ë³„ë¡œ", "ì•„ì‰½",
    "ë¦¬ì½œ", "íšŒìˆ˜", "ê¸‰ë°œì§„",
    "í‰ê¸°ì°¨", "í­íƒ„", "ì“°ë ˆê¸°",
    "ë¹„ì‹¸", "ë¹„ìŒˆ", "ë¶€ë‹´",
    "ì‹œë„ëŸ½", "ë–¨ë¦¼", "ì†ŒìŒ", "ì§„ë™",
]


class NaverBlogSentimentAnalyzer:
    """ë„¤ì´ë²„ ë¸”ë¡œê·¸ API ê¸°ë°˜ ê°ì„± ë¶„ì„"""
    
    def __init__(self, client_id=None, client_secret=None):
        """
        Args:
            client_id: ë„¤ì´ë²„ API Client ID
            client_secret: ë„¤ì´ë²„ API Client Secret
        """
        from dotenv import load_dotenv
        load_dotenv()
        
        self.client_id = client_id or os.getenv('NAVER_CLIENT_ID')
        self.client_secret = client_secret or os.getenv('NAVER_CLIENT_SECRET')
        
        if not self.client_id or not self.client_secret:
            print("âš ï¸ ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    def search_blogs(self, query, display=100):
        """
        ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ì–´
            display: ê²°ê³¼ ê°œìˆ˜ (ìµœëŒ€ 100)
            
        Returns:
            list: ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        if not self.client_id:
            return []
        
        url = "https://openapi.naver.com/v1/search/blog.json"
        
        headers = {
            "X-Naver-Client-Id": self.client_id,
            "X-Naver-Client-Secret": self.client_secret
        }
        
        params = {
            "query": query,
            "display": display,
            "sort": "sim"  # ì •í™•ë„ìˆœ
        }
        
        try:
            response = requests.get(url, headers=headers, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            items = data.get('items', [])
            
            print(f"  âœ“ ë„¤ì´ë²„ ë¸”ë¡œê·¸ {len(items)}ê°œ ê²€ìƒ‰ ì™„ë£Œ")
            
            return items
            
        except Exception as e:
            print(f"  âš ï¸ ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def analyze_sentiment(self, posts):
        """
        ê°ì„± ë¶„ì„
        
        Args:
            posts: ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            dict: ê°ì„± ë¶„ì„ ê²°ê³¼
        """
        if not posts:
            return {
                'score': 0,
                'positive_ratio': 0.5,
                'negative_ratio': 0.5,
                'neutral_ratio': 0.0,
                'trend': 'neutral',
                'total_posts': 0,
                'source': 'naver_blog_api'
            }
        
        pos_count = 0
        neg_count = 0
        total_score = 0
        
        for post in posts:
            # titleê³¼ description í•©ì¹˜ê¸°
            text = (post.get('title', '') + ' ' + post.get('description', '')).lower()
            
            # HTML íƒœê·¸ ì œê±°
            import re
            text = re.sub(r'<[^>]+>', '', text)
            
            # ê¸ì •/ë¶€ì • í‚¤ì›Œë“œ ì¹´ìš´íŠ¸
            pos_score = sum(1 for w in POSITIVE_KEYWORDS if w in text)
            neg_score = sum(1 for w in NEGATIVE_KEYWORDS if w in text)
            
            post_score = pos_score - neg_score
            total_score += post_score
            
            if post_score > 0:
                pos_count += 1
            elif post_score < 0:
                neg_count += 1
        
        total = len(posts)
        pos_ratio = pos_count / total if total > 0 else 0
        neg_ratio = neg_count / total if total > 0 else 0
        neu_ratio = 1 - pos_ratio - neg_ratio
        
        # ì ìˆ˜ ì •ê·œí™” (-10 ~ +10)
        avg_score = total_score / total if total > 0 else 0
        normalized_score = max(-10, min(10, avg_score))
        
        # ì¶”ì„¸ íŒë‹¨
        if normalized_score > 2:
            trend = 'positive'
        elif normalized_score < -2:
            trend = 'negative'
        else:
            trend = 'neutral'
        
        result = {
            'score': round(normalized_score, 1),
            'positive_ratio': round(pos_ratio, 2),
            'negative_ratio': round(neg_ratio, 2),
            'neutral_ratio': round(neu_ratio, 2),
            'trend': trend,
            'total_posts': total,
            'source': 'naver_blog_api'
        }
        
        print(f"\nğŸ“Š ê°ì„± ë¶„ì„ (ë„¤ì´ë²„ ë¸”ë¡œê·¸ API):")
        print(f"  ë¶„ì„ ëŒ€ìƒ: {total}ê°œ")
        print(f"  ê¸ì •: {result['positive_ratio']:.0%} | ë¶€ì •: {result['negative_ratio']:.0%}")
        print(f"  ì ìˆ˜: {result['score']:.1f}/10 ({result['trend']})")
        
        return result
    
    def collect_and_analyze(self, car_model, keywords_variations=None):
        """
        ë¸”ë¡œê·¸ ê²€ìƒ‰ + ê°ì„± ë¶„ì„ í†µí•©
        
        Args:
            car_model: ì°¨ëŸ‰ ëª¨ë¸ëª…
            keywords_variations: ì¶”ê°€ ê²€ìƒ‰ì–´ ë³€í˜• (ì„ íƒ)
            
        Returns:
            dict: ê°ì„± ë¶„ì„ ê²°ê³¼
        """
        if keywords_variations is None:
            keywords_variations = [
                f"{car_model}",
                f"{car_model} ì¤‘ê³ ì°¨",
                f"{car_model} ë¦¬ë·°",
                f"{car_model} í›„ê¸°"
            ]
        
        print(f"ğŸ” ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰: {car_model}")
        
        all_posts = []
        
        for keyword in keywords_variations:
            posts = self.search_blogs(keyword, display=50)
            all_posts.extend(posts)
            time.sleep(0.1)  # API í˜¸ì¶œ ê°„ê²©
        
        # ì¤‘ë³µ ì œê±° (ë§í¬ ê¸°ì¤€)
        unique_posts = []
        seen_links = set()
        for post in all_posts:
            link = post.get('link', '')
            if link not in seen_links:
                seen_links.add(link)
                unique_posts.append(post)
        
        print(f"  âœ“ ì´ {len(unique_posts)}ê°œ ê³ ìœ  í¬ìŠ¤íŠ¸")
        
        # ê°ì„± ë¶„ì„
        result = self.analyze_sentiment(unique_posts)
        
        return result


if __name__ == "__main__":
    print("=" * 80)
    print("ë„¤ì´ë²„ ë¸”ë¡œê·¸ API ê°ì„± ë¶„ì„ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    analyzer = NaverBlogSentimentAnalyzer()
    
    test_models = ["ê·¸ëœì €", "ì•„ë°˜ë–¼"]
    
    for model in test_models:
        print(f"\n{'='*80}")
        print(f"ğŸš— {model}")
        print(f"{'='*80}")
        
        result = analyzer.collect_and_analyze(model)
        
        print(f"\nìµœì¢… ì ìˆ˜: {result['score']:.1f}/10")
        print(f"ì¶”ì„¸: {result['trend']}")
