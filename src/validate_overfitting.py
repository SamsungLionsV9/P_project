"""
ê³¼ì í•© ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
- K-Fold Cross Validation
- Learning Curve ë¶„ì„
- ì‹¤ì œ ì˜ˆì¸¡ ìƒ˜í”Œ í™•ì¸
"""
import pandas as pd
import numpy as np
from sklearn.model_selection import cross_val_score, KFold, learning_curve
from sklearn.metrics import mean_absolute_error, r2_score
import joblib
import matplotlib.pyplot as plt
import seaborn as sns

plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

def validate_model(model_path, data_path, car_type):
    """
    ëª¨ë¸ ê³¼ì í•© ê²€ì¦
    
    Args:
        model_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        data_path: ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        car_type: 'domestic' or 'imported'
    """
    print(f"\n{'='*70}")
    print(f"  ğŸ” {car_type.upper()} ëª¨ë¸ ê³¼ì í•© ê²€ì¦")
    print(f"{'='*70}")
    
    # Load model
    pipeline = joblib.load(model_path)
    print(f"  âœ“ ëª¨ë¸ ë¡œë“œ: {model_path}")
    
    # Load data
    df = pd.read_csv(data_path)
    df = df[df['car_type'] == car_type.capitalize()]
    
    # Feature engineering (ê°„ë‹¨ ë²„ì „)
    current_year = 2025
    df['age'] = current_year - df['year']
    df['mileage_per_year'] = df['mileage'] / (df['age'] + 1)
    df['is_low_mileage'] = (df['mileage'] < 30000).astype(int)
    df['age_group'] = pd.cut(df['age'], 
                              bins=[-1, 1, 3, 5, 10, 100], 
                              labels=['new', 'semi_new', 'used', 'old', 'very_old'])
    df['brand_fuel'] = df['brand'] + '_' + df['fuel']
    model_counts = df['model_name'].value_counts()
    df['model_popularity'] = df['model_name'].map(model_counts)
    df['model_popularity_log'] = np.log1p(df['model_popularity'])
    df['is_eco'] = df['fuel'].str.contains('ì „ê¸°|í•˜ì´ë¸Œë¦¬ë“œ', na=False).astype(int)
    df['log_price'] = np.log1p(df['price'])
    
    if car_type == 'domestic':
        df['is_high_mileage'] = (df['mileage'] > 150000).astype(int)
        df['age_mileage_interaction'] = df['age'] * np.log1p(df['mileage'])
        brand_price_mean = df.groupby('brand')['price'].transform('mean')
        df['brand_price_tier'] = pd.cut(brand_price_mean, bins=3, labels=['budget', 'mid', 'premium'])
        
        # Filter outliers
        df = df[df['price'] <= 5000]
    else:  # imported
        luxury_brands = ['ë²¤ì¸ ', 'BMW', 'ì•„ìš°ë””', 'ë ‰ì„œìŠ¤', 'í¬ë¥´ì‰', 
                        'í˜ë¼ë¦¬', 'ëŒë³´ë¥´ê¸°ë‹ˆ', 'ë²¤í‹€ë¦¬', 'ë¡¤ìŠ¤ë¡œì´ìŠ¤', 'ë§¥ë¼ë Œ',
                        'ë§ˆì„¸ë¼í‹°', 'ì• ìŠ¤í„´ë§ˆí‹´']
        df['is_luxury'] = df['brand'].isin(luxury_brands).astype(int)
        df['is_ultra_premium'] = (df['price'] > 5000).astype(int)
        brand_price_mean = df.groupby('brand')['price'].transform('mean')
        df['brand_value'] = brand_price_mean
        df['price_vs_brand_avg'] = df['price'] / (brand_price_mean + 1)
        df['model_rarity'] = 1 / (df['model_popularity'] + 1)
    
    print(f"  ë°ì´í„°: {len(df):,}ê±´")
    
    # Prepare features
    categorical_features = ['brand', 'model_name', 'fuel', 'age_group', 'brand_fuel']
    if car_type == 'domestic' and 'brand_price_tier' in df.columns:
        categorical_features.append('brand_price_tier')
    categorical_features = [f for f in categorical_features if f in df.columns]
    
    numerical_features = ['age', 'mileage', 'mileage_per_year', 
                         'is_low_mileage', 'model_popularity_log', 'is_eco']
    
    if car_type == 'domestic' and 'is_high_mileage' in df.columns:
        numerical_features.extend(['is_high_mileage', 'age_mileage_interaction'])
    elif car_type == 'imported' and 'is_luxury' in df.columns:
        numerical_features.extend(['is_luxury', 'is_ultra_premium', 'brand_value', 
                                   'price_vs_brand_avg', 'model_rarity'])
    
    numerical_features = [f for f in numerical_features if f in df.columns]
    
    feature_cols = categorical_features + numerical_features
    X = df[feature_cols]
    y = df['log_price']
    y_actual = df['price']
    
    # ---------------------------------------------------------
    # 1. K-Fold Cross Validation (ê³¼ì í•© í•µì‹¬ ê²€ì¦)
    # ---------------------------------------------------------
    print(f"\n  ğŸ“Š K-Fold Cross Validation (k=5)")
    kfold = KFold(n_splits=5, shuffle=True, random_state=42)
    
    # RÂ² scores
    r2_scores = cross_val_score(pipeline, X, y, cv=kfold, scoring='r2', n_jobs=-1)
    print(f"     RÂ² scores: {r2_scores}")
    print(f"     í‰ê·  RÂ²: {r2_scores.mean():.4f} (Â±{r2_scores.std():.4f})")
    
    # MAE scores (negativeë¡œ ë‚˜ì˜¤ë¯€ë¡œ -1 ê³±í•¨)
    mae_scores = -cross_val_score(pipeline, X, y, cv=kfold, 
                                   scoring='neg_mean_absolute_error', n_jobs=-1)
    
    # Log scaleì—ì„œ ì‹¤ì œ ê°€ê²© scaleë¡œ ë³€í™˜
    mae_scores_actual = np.expm1(mae_scores)
    print(f"     MAE (ë§Œì›): {mae_scores_actual}")
    print(f"     í‰ê·  MAE: {mae_scores_actual.mean():.0f}ë§Œì› (Â±{mae_scores_actual.std():.0f})")
    
    # ---------------------------------------------------------
    # 2. ê³¼ì í•© íŒì •
    # ---------------------------------------------------------
    print(f"\n  ğŸ” ê³¼ì í•© ë¶„ì„:")
    
    # Train vs CV ë¹„êµ
    y_train_pred = pipeline.predict(X)
    y_train_pred_actual = np.expm1(y_train_pred)
    train_mae = mean_absolute_error(y_actual, y_train_pred_actual)
    train_r2 = r2_score(y_actual, y_train_pred_actual)
    
    cv_mae_mean = mae_scores_actual.mean()
    cv_r2_mean = r2_scores.mean()
    
    print(f"     Train MAE: {train_mae:.0f}ë§Œì›")
    print(f"     CV MAE:    {cv_mae_mean:.0f}ë§Œì›")
    print(f"     MAE ì¦ê°€ìœ¨: {(cv_mae_mean - train_mae) / train_mae * 100:.1f}%")
    
    print(f"\n     Train RÂ²: {train_r2:.4f}")
    print(f"     CV RÂ²:    {cv_r2_mean:.4f}")
    print(f"     RÂ² ê°ì†Œìœ¨: {(train_r2 - cv_r2_mean) / train_r2 * 100:.1f}%")
    
    # ê³¼ì í•© íŒì • ê¸°ì¤€
    mae_increase = (cv_mae_mean - train_mae) / train_mae * 100
    r2_decrease = (train_r2 - cv_r2_mean) / train_r2 * 100
    
    print(f"\n  ğŸ¯ ê³¼ì í•© íŒì •:")
    if mae_increase > 20 or r2_decrease > 5:
        print(f"     âš ï¸  ê³¼ì í•© ê°€ëŠ¥ì„± ë†’ìŒ!")
        print(f"        - MAE ì¦ê°€ìœ¨ {mae_increase:.1f}% (ê¸°ì¤€: >20%)")
        print(f"        - RÂ² ê°ì†Œìœ¨ {r2_decrease:.1f}% (ê¸°ì¤€: >5%)")
        overfitting = True
    elif mae_increase > 10 or r2_decrease > 2:
        print(f"     âš¡ ê²½ë¯¸í•œ ê³¼ì í•©")
        print(f"        - MAE ì¦ê°€ìœ¨ {mae_increase:.1f}% (ê¸°ì¤€: 10-20%)")
        print(f"        - RÂ² ê°ì†Œìœ¨ {r2_decrease:.1f}% (ê¸°ì¤€: 2-5%)")
        overfitting = False
    else:
        print(f"     âœ… ê³¼ì í•© ì—†ìŒ (ì–‘í˜¸)")
        print(f"        - MAE ì¦ê°€ìœ¨ {mae_increase:.1f}% (ê¸°ì¤€: <10%)")
        print(f"        - RÂ² ê°ì†Œìœ¨ {r2_decrease:.1f}% (ê¸°ì¤€: <2%)")
        overfitting = False
    
    # ---------------------------------------------------------
    # 3. ê°€ê²©ëŒ€ë³„ ì„±ëŠ¥ ë¶„ì„
    # ---------------------------------------------------------
    print(f"\n  ğŸ’° ê°€ê²©ëŒ€ë³„ ì˜ˆì¸¡ ì •í™•ë„:")
    
    y_pred_actual = np.expm1(pipeline.predict(X))
    
    price_ranges = [
        (0, 1000, "ì €ê°€ (<1000ë§Œì›)"),
        (1000, 3000, "ì¤‘ê°€ (1000-3000ë§Œì›)"),
        (3000, 5000, "ê³ ê°€ (3000-5000ë§Œì›)"),
        (5000, 10000, "ì´ˆê³ ê°€ (5000ë§Œì›-1ì–µ)"),
        (10000, 999999, "ìŠˆí¼ì¹´ (1ì–µ+)")
    ]
    
    for min_p, max_p, label in price_ranges:
        mask = (y_actual >= min_p) & (y_actual < max_p)
        if mask.sum() == 0:
            continue
        
        subset_mae = mean_absolute_error(y_actual[mask], y_pred_actual[mask])
        subset_mape = np.mean(np.abs((y_actual[mask] - y_pred_actual[mask]) / y_actual[mask])) * 100
        print(f"     {label:25s}: MAE {subset_mae:6.0f}ë§Œì›, MAPE {subset_mape:5.1f}%, N={mask.sum():,}")
    
    # ---------------------------------------------------------
    # 4. ìƒ˜í”Œ ì˜ˆì¸¡ í™•ì¸
    # ---------------------------------------------------------
    print(f"\n  ğŸ“‹ ì‹¤ì œ vs ì˜ˆì¸¡ ìƒ˜í”Œ (Random 10ê±´):")
    sample_idx = np.random.choice(len(df), min(10, len(df)), replace=False)
    
    for idx in sample_idx:
        actual = y_actual.iloc[idx]
        pred = y_pred_actual[idx]
        error = abs(actual - pred)
        error_pct = error / actual * 100
        
        brand = df.iloc[idx]['brand']
        model = df.iloc[idx]['model_name']
        year = df.iloc[idx]['year']
        
        print(f"     {brand:8s} {model:15s} ({year:.0f}ë…„): "
              f"ì‹¤ì œ {actual:6.0f}ë§Œì› | ì˜ˆì¸¡ {pred:6.0f}ë§Œì› | "
              f"ì˜¤ì°¨ {error:5.0f}ë§Œì› ({error_pct:4.1f}%)")
    
    return {
        'car_type': car_type,
        'train_mae': train_mae,
        'cv_mae': cv_mae_mean,
        'train_r2': train_r2,
        'cv_r2': cv_r2_mean,
        'overfitting': overfitting
    }

if __name__ == "__main__":
    print("\n" + "="*70)
    print("  ğŸ” ê³¼ì í•© ê²€ì¦ ì‹œìŠ¤í…œ")
    print("="*70)
    
    results = []
    
    # Domestic model
    domestic_result = validate_model(
        '../models/domestic_car_price_model.pkl',
        '../data/processed_encar_combined.csv',
        'domestic'
    )
    results.append(domestic_result)
    
    # Imported model
    imported_result = validate_model(
        '../models/imported_car_price_model.pkl',
        '../data/processed_encar_combined.csv',
        'imported'
    )
    results.append(imported_result)
    
    # Summary
    print("\n" + "="*70)
    print("  ğŸ“Š ìµœì¢… ê³¼ì í•© ê²€ì¦ ê²°ê³¼")
    print("="*70)
    
    summary_df = pd.DataFrame(results)
    print("\n" + summary_df.to_string(index=False))
    
    print("\nâœ… ê²€ì¦ ì™„ë£Œ!")
